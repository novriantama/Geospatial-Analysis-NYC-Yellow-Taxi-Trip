[2024-10-12T00:40:57.550+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-10-12T00:40:57.613+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_yellow_cab.etl_task manual__2024-10-12T00:13:45.785414+00:00 [queued]>
[2024-10-12T00:40:57.618+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_yellow_cab.etl_task manual__2024-10-12T00:13:45.785414+00:00 [queued]>
[2024-10-12T00:40:57.619+0000] {taskinstance.py:2306} INFO - Starting attempt 5 of 5
[2024-10-12T00:40:57.628+0000] {taskinstance.py:2330} INFO - Executing <Task(SparkSubmitOperator): etl_task> on 2024-10-12 00:13:45.785414+00:00
[2024-10-12T00:40:57.632+0000] {standard_task_runner.py:63} INFO - Started process 5194 to run task
[2024-10-12T00:40:57.650+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'etl_yellow_cab', 'etl_task', 'manual__2024-10-12T00:13:45.785414+00:00', '--job-id', '66', '--raw', '--subdir', 'DAGS_FOLDER/yellow-cab-batch.py', '--cfg-path', '/tmp/tmp75dh3irx']
[2024-10-12T00:40:57.660+0000] {standard_task_runner.py:91} INFO - Job 66: Subtask etl_task
[2024-10-12T00:40:57.699+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-10-12T00:40:57.778+0000] {task_command.py:426} INFO - Running <TaskInstance: etl_yellow_cab.etl_task manual__2024-10-12T00:13:45.785414+00:00 [running]> on host yellow-cab-airflow-scheduler
[2024-10-12T00:40:57.865+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='hafidz' AIRFLOW_CTX_DAG_ID='etl_yellow_cab' AIRFLOW_CTX_TASK_ID='etl_task' AIRFLOW_CTX_EXECUTION_DATE='2024-10-12T00:13:45.785414+00:00' AIRFLOW_CTX_TRY_NUMBER='5' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-10-12T00:13:45.785414+00:00'
[2024-10-12T00:40:57.866+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-10-12T00:40:57.892+0000] {base.py:84} INFO - Using connection ID 'spark_main' for task execution.
[2024-10-12T00:40:57.894+0000] {spark_submit.py:473} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.jars.packages=org.apache.sedona:sedona-python-adapter-3.0_2.12:1.2.0-incubating,org.datasyslab:geotools-wrapper:geotools-24.0 --conf spark.jars.repositories=https://repo1.maven.org/maven2/ --conf spark.executor.memory=4g --conf spark.driver.maxResultSize=4g --conf spark.driver.memory=2g --name arrow-spark --deploy-mode client /spark-scripts/taxi_etl.py
[2024-10-12T00:40:59.565+0000] {spark_submit.py:649} INFO - https://repo1.maven.org/maven2/ added as a remote repository with the name: repo-1
[2024-10-12T00:40:59.585+0000] {spark_submit.py:649} INFO - :: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-10-12T00:40:59.641+0000] {spark_submit.py:649} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2024-10-12T00:40:59.642+0000] {spark_submit.py:649} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2024-10-12T00:40:59.645+0000] {spark_submit.py:649} INFO - org.apache.sedona#sedona-python-adapter-3.0_2.12 added as a dependency
[2024-10-12T00:40:59.646+0000] {spark_submit.py:649} INFO - org.datasyslab#geotools-wrapper added as a dependency
[2024-10-12T00:40:59.646+0000] {spark_submit.py:649} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-0f621d7d-471f-4ca1-9800-3c9064f35e74;1.0
[2024-10-12T00:40:59.647+0000] {spark_submit.py:649} INFO - confs: [default]
[2024-10-12T00:40:59.766+0000] {spark_submit.py:649} INFO - found org.apache.sedona#sedona-python-adapter-3.0_2.12;1.2.0-incubating in central
[2024-10-12T00:40:59.789+0000] {spark_submit.py:649} INFO - found org.locationtech.jts#jts-core;1.18.0 in central
[2024-10-12T00:40:59.809+0000] {spark_submit.py:649} INFO - found org.wololo#jts2geojson;0.16.1 in central
[2024-10-12T00:40:59.838+0000] {spark_submit.py:649} INFO - found org.apache.sedona#sedona-core-3.0_2.12;1.2.0-incubating in central
[2024-10-12T00:40:59.855+0000] {spark_submit.py:649} INFO - found org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central
[2024-10-12T00:40:59.871+0000] {spark_submit.py:649} INFO - found org.apache.sedona#sedona-sql-3.0_2.12;1.2.0-incubating in central
[2024-10-12T00:40:59.886+0000] {spark_submit.py:649} INFO - found org.datasyslab#geotools-wrapper;geotools-24.0 in central
[2024-10-12T00:40:59.907+0000] {spark_submit.py:649} INFO - :: resolution report :: resolve 255ms :: artifacts dl 7ms
[2024-10-12T00:40:59.908+0000] {spark_submit.py:649} INFO - :: modules in use:
[2024-10-12T00:40:59.908+0000] {spark_submit.py:649} INFO - org.apache.sedona#sedona-core-3.0_2.12;1.2.0-incubating from central in [default]
[2024-10-12T00:40:59.908+0000] {spark_submit.py:649} INFO - org.apache.sedona#sedona-python-adapter-3.0_2.12;1.2.0-incubating from central in [default]
[2024-10-12T00:40:59.909+0000] {spark_submit.py:649} INFO - org.apache.sedona#sedona-sql-3.0_2.12;1.2.0-incubating from central in [default]
[2024-10-12T00:40:59.909+0000] {spark_submit.py:649} INFO - org.datasyslab#geotools-wrapper;geotools-24.0 from central in [default]
[2024-10-12T00:40:59.909+0000] {spark_submit.py:649} INFO - org.locationtech.jts#jts-core;1.18.0 from central in [default]
[2024-10-12T00:40:59.909+0000] {spark_submit.py:649} INFO - org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]
[2024-10-12T00:40:59.909+0000] {spark_submit.py:649} INFO - org.wololo#jts2geojson;0.16.1 from central in [default]
[2024-10-12T00:40:59.910+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2024-10-12T00:40:59.910+0000] {spark_submit.py:649} INFO - |                  |            modules            ||   artifacts   |
[2024-10-12T00:40:59.910+0000] {spark_submit.py:649} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2024-10-12T00:40:59.910+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2024-10-12T00:40:59.911+0000] {spark_submit.py:649} INFO - |      default     |   7   |   0   |   0   |   0   ||   7   |   0   |
[2024-10-12T00:40:59.911+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2024-10-12T00:40:59.913+0000] {spark_submit.py:649} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-0f621d7d-471f-4ca1-9800-3c9064f35e74
[2024-10-12T00:40:59.913+0000] {spark_submit.py:649} INFO - confs: [default]
[2024-10-12T00:40:59.917+0000] {spark_submit.py:649} INFO - 0 artifacts copied, 7 already retrieved (0kB/4ms)
[2024-10-12T00:41:00.092+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-10-12T00:41:02.291+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Running Spark version 3.5.1
[2024-10-12T00:41:02.292+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: OS info Linux, 6.10.4-linuxkit, aarch64
[2024-10-12T00:41:02.292+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Java version 17.0.12
[2024-10-12T00:41:02.301+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO ResourceUtils: ==============================================================
[2024-10-12T00:41:02.302+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-10-12T00:41:02.304+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO ResourceUtils: ==============================================================
[2024-10-12T00:41:02.305+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Submitted application: BigQueryETL
[2024-10-12T00:41:02.313+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-10-12T00:41:02.317+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO ResourceProfile: Limiting resource is cpu
[2024-10-12T00:41:02.317+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-10-12T00:41:02.346+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SecurityManager: Changing view acls to: airflow
[2024-10-12T00:41:02.346+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SecurityManager: Changing modify acls to: airflow
[2024-10-12T00:41:02.346+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SecurityManager: Changing view acls groups to:
[2024-10-12T00:41:02.346+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SecurityManager: Changing modify acls groups to:
[2024-10-12T00:41:02.346+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY
[2024-10-12T00:41:02.468+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO Utils: Successfully started service 'sparkDriver' on port 33783.
[2024-10-12T00:41:02.484+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkEnv: Registering MapOutputTracker
[2024-10-12T00:41:02.512+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkEnv: Registering BlockManagerMaster
[2024-10-12T00:41:02.522+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-10-12T00:41:02.522+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-10-12T00:41:02.524+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-10-12T00:41:02.541+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5538a934-b1b0-4372-9235-8cd6110fb2ea
[2024-10-12T00:41:02.549+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
[2024-10-12T00:41:02.558+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-10-12T00:41:02.630+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2024-10-12T00:41:02.662+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-10-12T00:41:02.692+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.sedona_sedona-python-adapter-3.0_2.12-1.2.0-incubating.jar at spark://yellow-cab-airflow-scheduler:33783/jars/org.apache.sedona_sedona-python-adapter-3.0_2.12-1.2.0-incubating.jar with timestamp 1728693662286
[2024-10-12T00:41:02.693+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.datasyslab_geotools-wrapper-geotools-24.0.jar at spark://yellow-cab-airflow-scheduler:33783/jars/org.datasyslab_geotools-wrapper-geotools-24.0.jar with timestamp 1728693662286
[2024-10-12T00:41:02.693+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.locationtech.jts_jts-core-1.18.0.jar at spark://yellow-cab-airflow-scheduler:33783/jars/org.locationtech.jts_jts-core-1.18.0.jar with timestamp 1728693662286
[2024-10-12T00:41:02.693+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wololo_jts2geojson-0.16.1.jar at spark://yellow-cab-airflow-scheduler:33783/jars/org.wololo_jts2geojson-0.16.1.jar with timestamp 1728693662286
[2024-10-12T00:41:02.697+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.sedona_sedona-core-3.0_2.12-1.2.0-incubating.jar at spark://yellow-cab-airflow-scheduler:33783/jars/org.apache.sedona_sedona-core-3.0_2.12-1.2.0-incubating.jar with timestamp 1728693662286
[2024-10-12T00:41:02.699+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.sedona_sedona-sql-3.0_2.12-1.2.0-incubating.jar at spark://yellow-cab-airflow-scheduler:33783/jars/org.apache.sedona_sedona-sql-3.0_2.12-1.2.0-incubating.jar with timestamp 1728693662286
[2024-10-12T00:41:02.700+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar at spark://yellow-cab-airflow-scheduler:33783/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar with timestamp 1728693662286
[2024-10-12T00:41:02.700+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.sedona_sedona-python-adapter-3.0_2.12-1.2.0-incubating.jar at spark://yellow-cab-airflow-scheduler:33783/files/org.apache.sedona_sedona-python-adapter-3.0_2.12-1.2.0-incubating.jar with timestamp 1728693662286
[2024-10-12T00:41:02.700+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.sedona_sedona-python-adapter-3.0_2.12-1.2.0-incubating.jar to /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/userFiles-c69cbd41-33e5-48f9-ac57-effe71e916e0/org.apache.sedona_sedona-python-adapter-3.0_2.12-1.2.0-incubating.jar
[2024-10-12T00:41:02.757+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.datasyslab_geotools-wrapper-geotools-24.0.jar at spark://yellow-cab-airflow-scheduler:33783/files/org.datasyslab_geotools-wrapper-geotools-24.0.jar with timestamp 1728693662286
[2024-10-12T00:41:02.757+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO Utils: Copying /home/airflow/.ivy2/jars/org.datasyslab_geotools-wrapper-geotools-24.0.jar to /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/userFiles-c69cbd41-33e5-48f9-ac57-effe71e916e0/org.datasyslab_geotools-wrapper-geotools-24.0.jar
[2024-10-12T00:41:02.945+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.locationtech.jts_jts-core-1.18.0.jar at spark://yellow-cab-airflow-scheduler:33783/files/org.locationtech.jts_jts-core-1.18.0.jar with timestamp 1728693662286
[2024-10-12T00:41:02.946+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:02 INFO Utils: Copying /home/airflow/.ivy2/jars/org.locationtech.jts_jts-core-1.18.0.jar to /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/userFiles-c69cbd41-33e5-48f9-ac57-effe71e916e0/org.locationtech.jts_jts-core-1.18.0.jar
[2024-10-12T00:41:03.006+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wololo_jts2geojson-0.16.1.jar at spark://yellow-cab-airflow-scheduler:33783/files/org.wololo_jts2geojson-0.16.1.jar with timestamp 1728693662286
[2024-10-12T00:41:03.008+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wololo_jts2geojson-0.16.1.jar to /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/userFiles-c69cbd41-33e5-48f9-ac57-effe71e916e0/org.wololo_jts2geojson-0.16.1.jar
[2024-10-12T00:41:03.037+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.sedona_sedona-core-3.0_2.12-1.2.0-incubating.jar at spark://yellow-cab-airflow-scheduler:33783/files/org.apache.sedona_sedona-core-3.0_2.12-1.2.0-incubating.jar with timestamp 1728693662286
[2024-10-12T00:41:03.038+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.sedona_sedona-core-3.0_2.12-1.2.0-incubating.jar to /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/userFiles-c69cbd41-33e5-48f9-ac57-effe71e916e0/org.apache.sedona_sedona-core-3.0_2.12-1.2.0-incubating.jar
[2024-10-12T00:41:03.064+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.sedona_sedona-sql-3.0_2.12-1.2.0-incubating.jar at spark://yellow-cab-airflow-scheduler:33783/files/org.apache.sedona_sedona-sql-3.0_2.12-1.2.0-incubating.jar with timestamp 1728693662286
[2024-10-12T00:41:03.064+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.sedona_sedona-sql-3.0_2.12-1.2.0-incubating.jar to /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/userFiles-c69cbd41-33e5-48f9-ac57-effe71e916e0/org.apache.sedona_sedona-sql-3.0_2.12-1.2.0-incubating.jar
[2024-10-12T00:41:03.094+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar at spark://yellow-cab-airflow-scheduler:33783/files/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar with timestamp 1728693662286
[2024-10-12T00:41:03.094+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO Utils: Copying /home/airflow/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar to /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/userFiles-c69cbd41-33e5-48f9-ac57-effe71e916e0/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar
[2024-10-12T00:41:03.181+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2024-10-12T00:41:03.204+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO TransportClientFactory: Successfully created connection to spark-master/172.24.0.2:7077 after 12 ms (0 ms spent in bootstraps)
[2024-10-12T00:41:03.290+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241012004103-0011
[2024-10-12T00:41:03.296+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241012004103-0011/0 on worker-20241011213037-172.24.0.3-36185 (172.24.0.3:36185) with 4 core(s)
[2024-10-12T00:41:03.298+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20241012004103-0011/0 on hostPort 172.24.0.3:36185 with 4 core(s), 4.0 GiB RAM
[2024-10-12T00:41:03.302+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34119.
[2024-10-12T00:41:03.302+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO NettyBlockTransferService: Server created on yellow-cab-airflow-scheduler:34119
[2024-10-12T00:41:03.302+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-10-12T00:41:03.308+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, yellow-cab-airflow-scheduler, 34119, None)
[2024-10-12T00:41:03.312+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO BlockManagerMasterEndpoint: Registering block manager yellow-cab-airflow-scheduler:34119 with 1048.8 MiB RAM, BlockManagerId(driver, yellow-cab-airflow-scheduler, 34119, None)
[2024-10-12T00:41:03.319+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, yellow-cab-airflow-scheduler, 34119, None)
[2024-10-12T00:41:03.320+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, yellow-cab-airflow-scheduler, 34119, None)
[2024-10-12T00:41:03.488+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2024-10-12T00:41:03.495+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241012004103-0011/0 is now RUNNING
[2024-10-12T00:41:03.672+0000] {spark_submit.py:649} INFO - /spark-scripts/taxi_etl.py:28: DeprecationWarning: Call to deprecated function registerAll (Deprecated since 1.4.1, use SedonaContext.create() instead.).
[2024-10-12T00:41:03.673+0000] {spark_submit.py:649} INFO - SedonaRegistrator.registerAll(spark)
[2024-10-12T00:41:03.678+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2024-10-12T00:41:03.679+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:03 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2024-10-12T00:41:05.420+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO CodeGenerator: Code generated in 111.664792 ms
[2024-10-12T00:41:05.477+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.24.0.3:52838) with ID 0,  ResourceProfileId 0
[2024-10-12T00:41:05.488+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2024-10-12T00:41:05.493+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-10-12T00:41:05.494+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2024-10-12T00:41:05.495+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO DAGScheduler: Parents of final stage: List()
[2024-10-12T00:41:05.495+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:05.496+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-10-12T00:41:05.516+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.24.0.3:41503 with 2.2 GiB RAM, BlockManagerId(0, 172.24.0.3, 41503, None)
[2024-10-12T00:41:05.568+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.0 KiB, free 1048.8 MiB)
[2024-10-12T00:41:05.602+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 1048.8 MiB)
[2024-10-12T00:41:05.605+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 5.7 KiB, free: 1048.8 MiB)
[2024-10-12T00:41:05.607+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:05.617+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-10-12T00:41:05.617+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2024-10-12T00:41:06.709+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.24.0.3, executor 0, partition 0, PROCESS_LOCAL, 9588 bytes)
[2024-10-12T00:41:06.850+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.24.0.3:41503 (size: 5.7 KiB, free: 2.2 GiB)
[2024-10-12T00:41:07.297+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 604 ms on 172.24.0.3 (executor 0) (1/1)
[2024-10-12T00:41:07.298+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2024-10-12T00:41:07.305+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.802 s
[2024-10-12T00:41:07.307+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: looking for newly runnable stages
[2024-10-12T00:41:07.307+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: running: Set()
[2024-10-12T00:41:07.308+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: waiting: Set()
[2024-10-12T00:41:07.308+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: failed: Set()
[2024-10-12T00:41:07.343+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 5.7 KiB, free: 1048.8 MiB)
[2024-10-12T00:41:07.348+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.24.0.3:41503 in memory (size: 5.7 KiB, free: 2.2 GiB)
[2024-10-12T00:41:07.353+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO CodeGenerator: Code generated in 11.472042 ms
[2024-10-12T00:41:07.379+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2024-10-12T00:41:07.380+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-10-12T00:41:07.381+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2024-10-12T00:41:07.381+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2024-10-12T00:41:07.381+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:07.382+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-10-12T00:41:07.387+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 1048.8 MiB)
[2024-10-12T00:41:07.389+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.8 MiB)
[2024-10-12T00:41:07.390+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 5.9 KiB, free: 1048.8 MiB)
[2024-10-12T00:41:07.390+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:07.391+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-10-12T00:41:07.392+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2024-10-12T00:41:07.397+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.24.0.3, executor 0, partition 0, NODE_LOCAL, 9391 bytes)
[2024-10-12T00:41:07.421+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.24.0.3:41503 (size: 5.9 KiB, free: 2.2 GiB)
[2024-10-12T00:41:07.468+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.24.0.3:52838
[2024-10-12T00:41:07.579+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 184 ms on 172.24.0.3 (executor 0) (1/1)
[2024-10-12T00:41:07.580+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2024-10-12T00:41:07.580+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.195 s
[2024-10-12T00:41:07.581+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-10-12T00:41:07.582+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2024-10-12T00:41:07.583+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.203981 s
[2024-10-12T00:41:07.712+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 5.9 KiB, free: 1048.8 MiB)
[2024-10-12T00:41:07.714+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.24.0.3:41503 in memory (size: 5.9 KiB, free: 2.2 GiB)
[2024-10-12T00:41:08.380+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
[2024-10-12T00:41:08.411+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
[2024-10-12T00:41:08.518+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO FileSourceStrategy: Pushed Filters:
[2024-10-12T00:41:08.518+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#14, None)) > 0)
[2024-10-12T00:41:08.546+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO CodeGenerator: Code generated in 10.995834 ms
[2024-10-12T00:41:08.555+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 204.8 KiB, free 1048.6 MiB)
[2024-10-12T00:41:08.567+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1048.6 MiB)
[2024-10-12T00:41:08.568+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 35.6 KiB, free: 1048.8 MiB)
[2024-10-12T00:41:08.569+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
[2024-10-12T00:41:08.575+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2024-10-12T00:41:08.602+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2024-10-12T00:41:08.604+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-10-12T00:41:08.607+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
[2024-10-12T00:41:08.608+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Parents of final stage: List()
[2024-10-12T00:41:08.608+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:08.608+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-10-12T00:41:08.615+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.5 KiB, free 1048.6 MiB)
[2024-10-12T00:41:08.616+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 1048.5 MiB)
[2024-10-12T00:41:08.617+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 6.4 KiB, free: 1048.8 MiB)
[2024-10-12T00:41:08.618+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:08.619+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-10-12T00:41:08.619+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2024-10-12T00:41:08.620+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.24.0.3, executor 0, partition 0, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:08.645+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.24.0.3:41503 (size: 6.4 KiB, free: 2.2 GiB)
[2024-10-12T00:41:08.784+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.24.0.3:41503 (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:08.940+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 321 ms on 172.24.0.3 (executor 0) (1/1)
[2024-10-12T00:41:08.941+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2024-10-12T00:41:08.943+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.335 s
[2024-10-12T00:41:08.944+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-10-12T00:41:08.944+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2024-10-12T00:41:08.944+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.340749 s
[2024-10-12T00:41:08.959+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO CodeGenerator: Code generated in 7.515458 ms
[2024-10-12T00:41:08.991+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO FileSourceStrategy: Pushed Filters:
[2024-10-12T00:41:08.991+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO FileSourceStrategy: Post-Scan Filters:
[2024-10-12T00:41:08.995+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 204.8 KiB, free 1048.3 MiB)
[2024-10-12T00:41:09.001+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1048.3 MiB)
[2024-10-12T00:41:09.002+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 35.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:09.002+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:0
[2024-10-12T00:41:09.003+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2024-10-12T00:41:09.033+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2024-10-12T00:41:09.034+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2024-10-12T00:41:09.034+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
[2024-10-12T00:41:09.034+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO DAGScheduler: Parents of final stage: List()
[2024-10-12T00:41:09.034+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:09.034+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-10-12T00:41:09.043+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 31.4 KiB, free 1048.3 MiB)
[2024-10-12T00:41:09.049+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 1048.3 MiB)
[2024-10-12T00:41:09.050+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 6.4 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:09.050+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 13.7 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:09.051+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:09.051+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO DAGScheduler: Submitting 13 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2024-10-12T00:41:09.052+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO TaskSchedulerImpl: Adding task set 4.0 with 13 tasks resource profile 0
[2024-10-12T00:41:09.052+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.24.0.3, executor 0, partition 0, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:09.054+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 4) (172.24.0.3, executor 0, partition 1, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:09.055+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 5) (172.24.0.3, executor 0, partition 2, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:09.055+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 6) (172.24.0.3, executor 0, partition 3, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:09.056+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.24.0.3:41503 in memory (size: 6.4 KiB, free: 2.2 GiB)
[2024-10-12T00:41:09.076+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.24.0.3:41503 (size: 13.7 KiB, free: 2.2 GiB)
[2024-10-12T00:41:09.861+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.24.0.3:41503 (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:13.916+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:13 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 7) (172.24.0.3, executor 0, partition 4, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:13.922+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:13 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 8) (172.24.0.3, executor 0, partition 5, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:13.923+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:13 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 9) (172.24.0.3, executor 0, partition 6, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:13.924+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 4872 ms on 172.24.0.3 (executor 0) (1/13)
[2024-10-12T00:41:13.925+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:13 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 4) in 4872 ms on 172.24.0.3 (executor 0) (2/13)
[2024-10-12T00:41:13.926+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:13 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 6) in 4872 ms on 172.24.0.3 (executor 0) (3/13)
[2024-10-12T00:41:14.200+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:14 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 10) (172.24.0.3, executor 0, partition 7, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:14.202+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:14 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 5) in 5148 ms on 172.24.0.3 (executor 0) (4/13)
[2024-10-12T00:41:16.555+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 11) (172.24.0.3, executor 0, partition 8, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:16.563+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 12) (172.24.0.3, executor 0, partition 9, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:16.564+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 7) in 2648 ms on 172.24.0.3 (executor 0) (5/13)
[2024-10-12T00:41:16.565+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 9) in 2637 ms on 172.24.0.3 (executor 0) (6/13)
[2024-10-12T00:41:16.686+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Starting task 10.0 in stage 4.0 (TID 13) (172.24.0.3, executor 0, partition 10, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:16.688+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 10) in 2489 ms on 172.24.0.3 (executor 0) (7/13)
[2024-10-12T00:41:16.933+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Starting task 11.0 in stage 4.0 (TID 14) (172.24.0.3, executor 0, partition 11, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:16.934+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:16 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 8) in 3016 ms on 172.24.0.3 (executor 0) (8/13)
[2024-10-12T00:41:19.735+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:19 INFO TaskSetManager: Starting task 12.0 in stage 4.0 (TID 15) (172.24.0.3, executor 0, partition 12, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:19.740+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:19 INFO TaskSetManager: Finished task 10.0 in stage 4.0 (TID 13) in 3055 ms on 172.24.0.3 (executor 0) (9/13)
[2024-10-12T00:41:19.745+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:19 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 11) in 3197 ms on 172.24.0.3 (executor 0) (10/13)
[2024-10-12T00:41:19.772+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:19 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 12) in 3214 ms on 172.24.0.3 (executor 0) (11/13)
[2024-10-12T00:41:19.892+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:19 INFO TaskSetManager: Finished task 11.0 in stage 4.0 (TID 14) in 2960 ms on 172.24.0.3 (executor 0) (12/13)
[2024-10-12T00:41:21.038+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO TaskSetManager: Finished task 12.0 in stage 4.0 (TID 15) in 1312 ms on 172.24.0.3 (executor 0) (13/13)
[2024-10-12T00:41:21.038+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2024-10-12T00:41:21.039+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 12.003 s
[2024-10-12T00:41:21.040+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-10-12T00:41:21.040+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2024-10-12T00:41:21.041+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 12.008405 s
[2024-10-12T00:41:21.475+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO FileSourceStrategy: Pushed Filters:
[2024-10-12T00:41:21.476+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO FileSourceStrategy: Post-Scan Filters: atleastnnonnulls(4, tpep_pickup_datetime#32, tpep_dropoff_datetime#33, pickup_longitude#36, pickup_latitude#37)
[2024-10-12T00:41:21.543+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO CodeGenerator: Code generated in 26.638375 ms
[2024-10-12T00:41:21.547+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 204.7 KiB, free 1048.1 MiB)
[2024-10-12T00:41:21.569+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1048.1 MiB)
[2024-10-12T00:41:21.571+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 35.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:21.572+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO SparkContext: Created broadcast 6 from showString at NativeMethodAccessorImpl.java:0
[2024-10-12T00:41:21.572+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO BlockManagerInfo: Removed broadcast_5_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 13.7 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:21.581+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.24.0.3:41503 in memory (size: 13.7 KiB, free: 2.2 GiB)
[2024-10-12T00:41:21.583+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2024-10-12T00:41:21.598+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2024-10-12T00:41:21.602+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-10-12T00:41:21.603+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)
[2024-10-12T00:41:21.603+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Parents of final stage: List()
[2024-10-12T00:41:21.603+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:21.603+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-10-12T00:41:21.613+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.0 KiB, free 1048.1 MiB)
[2024-10-12T00:41:21.615+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 1048.0 MiB)
[2024-10-12T00:41:21.616+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 16.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:21.616+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:21.617+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-10-12T00:41:21.617+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2024-10-12T00:41:21.618+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 16) (172.24.0.3, executor 0, partition 0, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:41:21.631+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.24.0.3:41503 (size: 16.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:21.963+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.24.0.3:41503 (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:22.057+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 16) in 438 ms on 172.24.0.3 (executor 0) (1/1)
[2024-10-12T00:41:22.060+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2024-10-12T00:41:22.061+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.457 s
[2024-10-12T00:41:22.061+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-10-12T00:41:22.061+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2024-10-12T00:41:22.062+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.460124 s
[2024-10-12T00:41:22.109+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO CodeGenerator: Code generated in 30.736208 ms
[2024-10-12T00:41:22.120+0000] {spark_submit.py:649} INFO - +--------+------------+------------------+------------------+------------------+------------------+--------------------+---------------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+-------------+------------------+--------------------+--------------------+------------------------+
[2024-10-12T00:41:22.121+0000] {spark_submit.py:649} INFO - |VendorID|payment_type|  pickup_longitude|   pickup_latitude| dropoff_longitude|  dropoff_latitude|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|Trip_Duration|store_and_fwd_flag|   Pickup_Point_EWKT|  Dropoff_Point_EWKT|Trip_Distance_Calculated|
[2024-10-12T00:41:22.122+0000] {spark_submit.py:649} INFO - +--------+------------+------------------+------------------+------------------+------------------+--------------------+---------------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+-------------+------------------+--------------------+--------------------+------------------------+
[2024-10-12T00:41:22.122+0000] {spark_submit.py:649} INFO - |       2|           2|-73.99037170410156| 40.73469543457031|-73.98184204101562| 40.73240661621094| 2016-01-01 00:00:00|  2016-01-01 00:00:00|              2|          1.1|        7.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.8|          0.0|                 N|POINT (-73.990371...|POINT (-73.981842...|    0.008831412222392119|
[2024-10-12T00:41:22.123+0000] {spark_submit.py:649} INFO - |       2|           1|-73.98078155517578| 40.72991180419922|-73.94447326660156|40.716678619384766| 2016-01-01 00:00:00|  2016-01-01 00:00:00|              5|          4.9|       18.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        19.3|          0.0|                 N|POINT (-73.980781...|POINT (-73.944473...|    0.038644650335100936|
[2024-10-12T00:41:22.123+0000] {spark_submit.py:649} INFO - |       2|           1|-73.98455047607422|  40.6795654296875|-73.95027160644531| 40.78892517089844| 2016-01-01 00:00:00|  2016-01-01 00:00:00|              1|        10.54|       33.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        34.3|          0.0|                 N|POINT (-73.984550...|POINT (-73.950271...|     0.11460625594075907|
[2024-10-12T00:41:22.123+0000] {spark_submit.py:649} INFO - |       2|           2|-73.99346923828125|40.718990325927734|-73.96224212646484| 40.65733337402344| 2016-01-01 00:00:00|  2016-01-01 00:00:00|              1|         4.75|       16.5|  0.0|    0.5|       0.0|         0.0|                  0.3|        17.3|          0.0|                 N|POINT (-73.993469...|POINT (-73.962242...|     0.06911376296023186|
[2024-10-12T00:41:22.124+0000] {spark_submit.py:649} INFO - |       2|           2|-73.96062469482422| 40.78133010864258|-73.97726440429688|40.758514404296875| 2016-01-01 00:00:00|  2016-01-01 00:00:00|              3|         1.76|        8.0|  0.0|    0.5|       0.0|         0.0|                  0.3|         8.8|          0.0|                 N|POINT (-73.960624...|POINT (-73.977264...|    0.028238914570587564|
[2024-10-12T00:41:22.124+0000] {spark_submit.py:649} INFO - |       2|           2|-73.98011779785156| 40.74304962158203|-73.91349029541016| 40.76314163208008| 2016-01-01 00:00:00|  2016-01-01 00:18:30|              2|         5.52|       19.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        20.3|         18.5|                 N|POINT (-73.980117...|POINT (-73.913490...|      0.0695910408560845|
[2024-10-12T00:41:22.124+0000] {spark_submit.py:649} INFO - |       2|           2|-73.99405670166016| 40.71998977661133|-73.96636199951172| 40.78987121582031| 2016-01-01 00:00:00|  2016-01-01 00:26:45|              2|         7.45|       26.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        27.3|        26.75|                 N|POINT (-73.994056...|POINT (-73.966361...|     0.07516922291077412|
[2024-10-12T00:41:22.124+0000] {spark_submit.py:649} INFO - |       1|           2|-73.97942352294922| 40.74461364746094|-73.99203491210938|40.753944396972656| 2016-01-01 00:00:01|  2016-01-01 00:11:55|              1|          1.2|        9.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        10.3|         11.9|                 N|POINT (-73.979423...|POINT (-73.992034...|    0.015687894154390074|
[2024-10-12T00:41:22.125+0000] {spark_submit.py:649} INFO - |       1|           2|-73.94715118408203|40.791046142578125|-73.92076873779297|40.865577697753906| 2016-01-01 00:00:02|  2016-01-01 00:11:14|              1|          6.0|       18.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        19.3|         11.2|                 N|POINT (-73.947151...|POINT (-73.920768...|     0.07906317846580539|
[2024-10-12T00:41:22.125+0000] {spark_submit.py:649} INFO - |       2|           2|-73.99834442138672| 40.72389602661133|  -73.995849609375| 40.68840026855469| 2016-01-01 00:00:02|  2016-01-01 00:11:08|              1|         3.21|       11.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.8|         11.1|                 N|POINT (-73.998344...|POINT (-73.995849...|    0.035583323720380367|
[2024-10-12T00:41:22.125+0000] {spark_submit.py:649} INFO - +--------+------------+------------------+------------------+------------------+------------------+--------------------+---------------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+-------------+------------------+--------------------+--------------------+------------------------+
[2024-10-12T00:41:22.126+0000] {spark_submit.py:649} INFO - only showing top 10 rows
[2024-10-12T00:41:22.126+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:41:22.600+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO FileSourceStrategy: Pushed Filters:
[2024-10-12T00:41:22.604+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO FileSourceStrategy: Post-Scan Filters: atleastnnonnulls(4, tpep_pickup_datetime#32, tpep_dropoff_datetime#33, pickup_longitude#36, pickup_latitude#37)
[2024-10-12T00:41:22.693+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO CodeGenerator: Code generated in 48.370208 ms
[2024-10-12T00:41:22.695+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 204.7 KiB, free 1047.8 MiB)
[2024-10-12T00:41:22.703+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 35.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:22.705+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1048.0 MiB)
[2024-10-12T00:41:22.708+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 35.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:22.709+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO SparkContext: Created broadcast 8 from toPandas at /spark-scripts/taxi_etl.py:119
[2024-10-12T00:41:22.710+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2024-10-12T00:41:22.712+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.24.0.3:41503 in memory (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:22.718+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Removed broadcast_7_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 16.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:22.718+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Registering RDD 25 (toPandas at /spark-scripts/taxi_etl.py:119) as input to shuffle 1
[2024-10-12T00:41:22.719+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Got map stage job 5 (toPandas at /spark-scripts/taxi_etl.py:119) with 13 output partitions
[2024-10-12T00:41:22.719+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (toPandas at /spark-scripts/taxi_etl.py:119)
[2024-10-12T00:41:22.720+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Parents of final stage: List()
[2024-10-12T00:41:22.720+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:22.721+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[25] at toPandas at /spark-scripts/taxi_etl.py:119), which has no missing parents
[2024-10-12T00:41:22.721+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.24.0.3:41503 in memory (size: 16.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:22.722+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 33.0 KiB, free 1048.1 MiB)
[2024-10-12T00:41:22.727+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KiB, free 1048.0 MiB)
[2024-10-12T00:41:22.728+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 15.0 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:22.729+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:22.729+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[25] at toPandas at /spark-scripts/taxi_etl.py:119) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2024-10-12T00:41:22.729+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSchedulerImpl: Adding task set 6.0 with 13 tasks resource profile 0
[2024-10-12T00:41:22.730+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 17) (172.24.0.3, executor 0, partition 0, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:22.730+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 18) (172.24.0.3, executor 0, partition 1, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:22.731+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 19) (172.24.0.3, executor 0, partition 2, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:22.731+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 20) (172.24.0.3, executor 0, partition 3, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:22.763+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.24.0.3:41503 (size: 15.0 KiB, free: 2.2 GiB)
[2024-10-12T00:41:22.958+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.24.0.3:41503 (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:24.937+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 21) (172.24.0.3, executor 0, partition 4, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:24.945+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 20) in 2205 ms on 172.24.0.3 (executor 0) (1/13)
[2024-10-12T00:41:24.945+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Starting task 5.0 in stage 6.0 (TID 22) (172.24.0.3, executor 0, partition 5, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:24.948+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 17) in 2210 ms on 172.24.0.3 (executor 0) (2/13)
[2024-10-12T00:41:24.948+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Starting task 6.0 in stage 6.0 (TID 23) (172.24.0.3, executor 0, partition 6, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:24.950+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 19) in 2214 ms on 172.24.0.3 (executor 0) (3/13)
[2024-10-12T00:41:24.954+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Starting task 7.0 in stage 6.0 (TID 24) (172.24.0.3, executor 0, partition 7, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:24.956+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:24 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 18) in 2216 ms on 172.24.0.3 (executor 0) (4/13)
[2024-10-12T00:41:27.482+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Starting task 8.0 in stage 6.0 (TID 25) (172.24.0.3, executor 0, partition 8, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:27.491+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Finished task 6.0 in stage 6.0 (TID 23) in 2541 ms on 172.24.0.3 (executor 0) (5/13)
[2024-10-12T00:41:27.493+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Starting task 9.0 in stage 6.0 (TID 26) (172.24.0.3, executor 0, partition 9, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:27.494+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Starting task 10.0 in stage 6.0 (TID 27) (172.24.0.3, executor 0, partition 10, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:27.496+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Starting task 11.0 in stage 6.0 (TID 28) (172.24.0.3, executor 0, partition 11, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:27.497+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 21) in 2557 ms on 172.24.0.3 (executor 0) (6/13)
[2024-10-12T00:41:27.499+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Finished task 7.0 in stage 6.0 (TID 24) in 2544 ms on 172.24.0.3 (executor 0) (7/13)
[2024-10-12T00:41:27.499+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:27 INFO TaskSetManager: Finished task 5.0 in stage 6.0 (TID 22) in 2552 ms on 172.24.0.3 (executor 0) (8/13)
[2024-10-12T00:41:30.032+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:30 INFO TaskSetManager: Starting task 12.0 in stage 6.0 (TID 29) (172.24.0.3, executor 0, partition 12, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:30.040+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:30 INFO TaskSetManager: Finished task 9.0 in stage 6.0 (TID 26) in 2549 ms on 172.24.0.3 (executor 0) (9/13)
[2024-10-12T00:41:30.043+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:30 INFO TaskSetManager: Finished task 11.0 in stage 6.0 (TID 28) in 2547 ms on 172.24.0.3 (executor 0) (10/13)
[2024-10-12T00:41:30.044+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:30 INFO TaskSetManager: Finished task 8.0 in stage 6.0 (TID 25) in 2559 ms on 172.24.0.3 (executor 0) (11/13)
[2024-10-12T00:41:30.045+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:30 INFO TaskSetManager: Finished task 10.0 in stage 6.0 (TID 27) in 2549 ms on 172.24.0.3 (executor 0) (12/13)
[2024-10-12T00:41:31.257+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO TaskSetManager: Finished task 12.0 in stage 6.0 (TID 29) in 1228 ms on 172.24.0.3 (executor 0) (13/13)
[2024-10-12T00:41:31.263+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2024-10-12T00:41:31.266+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: ShuffleMapStage 6 (toPandas at /spark-scripts/taxi_etl.py:119) finished in 8.538 s
[2024-10-12T00:41:31.267+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: looking for newly runnable stages
[2024-10-12T00:41:31.268+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: running: Set()
[2024-10-12T00:41:31.269+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: waiting: Set()
[2024-10-12T00:41:31.271+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: failed: Set()
[2024-10-12T00:41:31.377+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2024-10-12T00:41:31.463+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO CodeGenerator: Code generated in 53.268583 ms
[2024-10-12T00:41:31.482+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO SparkContext: Starting job: toPandas at /spark-scripts/taxi_etl.py:119
[2024-10-12T00:41:31.483+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Got job 6 (toPandas at /spark-scripts/taxi_etl.py:119) with 1 output partitions
[2024-10-12T00:41:31.483+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Final stage: ResultStage 8 (toPandas at /spark-scripts/taxi_etl.py:119)
[2024-10-12T00:41:31.484+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2024-10-12T00:41:31.485+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:31.486+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[28] at toPandas at /spark-scripts/taxi_etl.py:119), which has no missing parents
[2024-10-12T00:41:31.488+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 45.4 KiB, free 1048.0 MiB)
[2024-10-12T00:41:31.501+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 1048.0 MiB)
[2024-10-12T00:41:31.503+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 21.0 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:31.503+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:31.504+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[28] at toPandas at /spark-scripts/taxi_etl.py:119) (first 15 tasks are for partitions Vector(0))
[2024-10-12T00:41:31.505+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2024-10-12T00:41:31.505+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 15.0 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:31.508+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 30) (172.24.0.3, executor 0, partition 0, NODE_LOCAL, 9391 bytes)
[2024-10-12T00:41:31.510+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.24.0.3:41503 in memory (size: 15.0 KiB, free: 2.2 GiB)
[2024-10-12T00:41:31.541+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.24.0.3:41503 (size: 21.0 KiB, free: 2.2 GiB)
[2024-10-12T00:41:31.586+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.24.0.3:52838
[2024-10-12T00:41:31.635+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 30) in 130 ms on 172.24.0.3 (executor 0) (1/1)
[2024-10-12T00:41:31.636+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2024-10-12T00:41:31.636+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: ResultStage 8 (toPandas at /spark-scripts/taxi_etl.py:119) finished in 0.150 s
[2024-10-12T00:41:31.637+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-10-12T00:41:31.637+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2024-10-12T00:41:31.638+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:31 INFO DAGScheduler: Job 6 finished: toPandas at /spark-scripts/taxi_etl.py:119, took 0.154354 s
[2024-10-12T00:41:35.480+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO FileSourceStrategy: Pushed Filters:
[2024-10-12T00:41:35.486+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO FileSourceStrategy: Post-Scan Filters: atleastnnonnulls(4, tpep_pickup_datetime#32, tpep_dropoff_datetime#33, pickup_longitude#36, pickup_latitude#37)
[2024-10-12T00:41:35.535+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO CodeGenerator: Code generated in 29.3115 ms
[2024-10-12T00:41:35.540+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 204.7 KiB, free 1047.8 MiB)
[2024-10-12T00:41:35.566+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1047.8 MiB)
[2024-10-12T00:41:35.571+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 35.6 KiB, free: 1048.6 MiB)
[2024-10-12T00:41:35.573+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO SparkContext: Created broadcast 11 from toPandas at /spark-scripts/taxi_etl.py:122
[2024-10-12T00:41:35.584+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2024-10-12T00:41:35.596+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO DAGScheduler: Registering RDD 32 (toPandas at /spark-scripts/taxi_etl.py:122) as input to shuffle 2
[2024-10-12T00:41:35.597+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO DAGScheduler: Got map stage job 7 (toPandas at /spark-scripts/taxi_etl.py:122) with 13 output partitions
[2024-10-12T00:41:35.597+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (toPandas at /spark-scripts/taxi_etl.py:122)
[2024-10-12T00:41:35.598+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO DAGScheduler: Parents of final stage: List()
[2024-10-12T00:41:35.599+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:35.599+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[32] at toPandas at /spark-scripts/taxi_etl.py:122), which has no missing parents
[2024-10-12T00:41:35.603+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 32.7 KiB, free 1047.8 MiB)
[2024-10-12T00:41:35.606+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1047.7 MiB)
[2024-10-12T00:41:35.608+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 14.8 KiB, free: 1048.6 MiB)
[2024-10-12T00:41:35.608+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:35.609+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[32] at toPandas at /spark-scripts/taxi_etl.py:122) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2024-10-12T00:41:35.610+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO TaskSchedulerImpl: Adding task set 9.0 with 13 tasks resource profile 0
[2024-10-12T00:41:35.612+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 31) (172.24.0.3, executor 0, partition 0, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:35.613+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 32) (172.24.0.3, executor 0, partition 1, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:35.613+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 33) (172.24.0.3, executor 0, partition 2, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:35.613+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 34) (172.24.0.3, executor 0, partition 3, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:35.686+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.24.0.3:41503 (size: 14.8 KiB, free: 2.2 GiB)
[2024-10-12T00:41:35.789+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.24.0.3:41503 (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:38.721+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:38 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 35) (172.24.0.3, executor 0, partition 4, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:38.732+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:38 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 34) in 3107 ms on 172.24.0.3 (executor 0) (1/13)
[2024-10-12T00:41:38.734+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:38 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 36) (172.24.0.3, executor 0, partition 5, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:38.735+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:38 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 31) in 3114 ms on 172.24.0.3 (executor 0) (2/13)
[2024-10-12T00:41:38.759+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:38 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 37) (172.24.0.3, executor 0, partition 6, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:38.762+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:38 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 33) in 3149 ms on 172.24.0.3 (executor 0) (3/13)
[2024-10-12T00:41:40.016+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:40 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 38) (172.24.0.3, executor 0, partition 7, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:40.018+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:40 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 32) in 4406 ms on 172.24.0.3 (executor 0) (4/13)
[2024-10-12T00:41:41.483+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:41 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 39) (172.24.0.3, executor 0, partition 8, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:41.493+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:41 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 37) in 2724 ms on 172.24.0.3 (executor 0) (5/13)
[2024-10-12T00:41:41.513+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:41 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 40) (172.24.0.3, executor 0, partition 9, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:41.519+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:41 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 35) in 2811 ms on 172.24.0.3 (executor 0) (6/13)
[2024-10-12T00:41:41.536+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:41 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 41) (172.24.0.3, executor 0, partition 10, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:41.538+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:41 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 36) in 2815 ms on 172.24.0.3 (executor 0) (7/13)
[2024-10-12T00:41:43.002+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:42 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 42) (172.24.0.3, executor 0, partition 11, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:43.008+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:43 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 38) in 2987 ms on 172.24.0.3 (executor 0) (8/13)
[2024-10-12T00:41:44.253+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:44 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 43) (172.24.0.3, executor 0, partition 12, PROCESS_LOCAL, 9983 bytes)
[2024-10-12T00:41:44.261+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:44 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 40) in 2748 ms on 172.24.0.3 (executor 0) (9/13)
[2024-10-12T00:41:44.266+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:44 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 39) in 2798 ms on 172.24.0.3 (executor 0) (10/13)
[2024-10-12T00:41:44.310+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:44 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 41) in 2775 ms on 172.24.0.3 (executor 0) (11/13)
[2024-10-12T00:41:45.620+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:45 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 42) in 2616 ms on 172.24.0.3 (executor 0) (12/13)
[2024-10-12T00:41:46.242+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 43) in 2000 ms on 172.24.0.3 (executor 0) (13/13)
[2024-10-12T00:41:46.243+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2024-10-12T00:41:46.246+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: ShuffleMapStage 9 (toPandas at /spark-scripts/taxi_etl.py:122) finished in 10.645 s
[2024-10-12T00:41:46.247+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: looking for newly runnable stages
[2024-10-12T00:41:46.248+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: running: Set()
[2024-10-12T00:41:46.249+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: waiting: Set()
[2024-10-12T00:41:46.249+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: failed: Set()
[2024-10-12T00:41:46.266+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 4997122, minimum partition size: 1048576
[2024-10-12T00:41:46.380+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO CodeGenerator: Code generated in 51.960583 ms
[2024-10-12T00:41:46.429+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO SparkContext: Starting job: toPandas at /spark-scripts/taxi_etl.py:122
[2024-10-12T00:41:46.430+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: Got job 8 (toPandas at /spark-scripts/taxi_etl.py:122) with 4 output partitions
[2024-10-12T00:41:46.431+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: Final stage: ResultStage 11 (toPandas at /spark-scripts/taxi_etl.py:122)
[2024-10-12T00:41:46.431+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2024-10-12T00:41:46.432+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:41:46.432+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[35] at toPandas at /spark-scripts/taxi_etl.py:122), which has no missing parents
[2024-10-12T00:41:46.452+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 55.2 KiB, free 1047.7 MiB)
[2024-10-12T00:41:46.456+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 1047.7 MiB)
[2024-10-12T00:41:46.457+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 23.9 KiB, free: 1048.6 MiB)
[2024-10-12T00:41:46.458+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:41:46.459+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[35] at toPandas at /spark-scripts/taxi_etl.py:122) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2024-10-12T00:41:46.460+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks resource profile 0
[2024-10-12T00:41:46.462+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 44) (172.24.0.3, executor 0, partition 0, NODE_LOCAL, 9391 bytes)
[2024-10-12T00:41:46.462+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 45) (172.24.0.3, executor 0, partition 1, NODE_LOCAL, 9391 bytes)
[2024-10-12T00:41:46.463+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 46) (172.24.0.3, executor 0, partition 2, NODE_LOCAL, 9391 bytes)
[2024-10-12T00:41:46.463+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 47) (172.24.0.3, executor 0, partition 3, NODE_LOCAL, 9391 bytes)
[2024-10-12T00:41:46.505+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.24.0.3:41503 (size: 23.9 KiB, free: 2.2 GiB)
[2024-10-12T00:41:46.576+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.24.0.3:52838
[2024-10-12T00:41:47.898+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:47 INFO BlockManagerInfo: Added taskresult_45 in memory on 172.24.0.3:41503 (size: 8.6 MiB, free: 2.2 GiB)
[2024-10-12T00:41:47.919+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:47 INFO BlockManagerInfo: Added taskresult_44 in memory on 172.24.0.3:41503 (size: 8.5 MiB, free: 2.2 GiB)
[2024-10-12T00:41:47.921+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:47 INFO BlockManagerInfo: Added taskresult_47 in memory on 172.24.0.3:41503 (size: 8.8 MiB, free: 2.2 GiB)
[2024-10-12T00:41:47.922+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:47 INFO BlockManagerInfo: Added taskresult_46 in memory on 172.24.0.3:41503 (size: 8.6 MiB, free: 2.2 GiB)
[2024-10-12T00:41:48.020+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO TransportClientFactory: Successfully created connection to /172.24.0.3:41503 after 4 ms (0 ms spent in bootstraps)
[2024-10-12T00:41:48.165+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 44) in 1702 ms on 172.24.0.3 (executor 0) (1/4)
[2024-10-12T00:41:48.170+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_12_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 14.8 KiB, free: 1048.6 MiB)
[2024-10-12T00:41:48.177+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.24.0.3:41503 in memory (size: 14.8 KiB, free: 2.2 GiB)
[2024-10-12T00:41:48.184+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed taskresult_44 on 172.24.0.3:41503 in memory (size: 8.5 MiB, free: 2.2 GiB)
[2024-10-12T00:41:48.201+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_10_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 21.0 KiB, free: 1048.6 MiB)
[2024-10-12T00:41:48.224+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.24.0.3:41503 in memory (size: 21.0 KiB, free: 2.2 GiB)
[2024-10-12T00:41:48.225+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 45) in 1761 ms on 172.24.0.3 (executor 0) (2/4)
[2024-10-12T00:41:48.231+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed taskresult_45 on 172.24.0.3:41503 in memory (size: 8.6 MiB, free: 2.2 GiB)
[2024-10-12T00:41:48.293+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 46) in 1830 ms on 172.24.0.3 (executor 0) (3/4)
[2024-10-12T00:41:48.301+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed taskresult_46 on 172.24.0.3:41503 in memory (size: 8.6 MiB, free: 2.2 GiB)
[2024-10-12T00:41:48.485+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_4_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 35.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:48.533+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.24.0.3:41503 in memory (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:48.553+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_2_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 35.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:48.556+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.24.0.3:41503 in memory (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:41:48.566+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 47) in 2102 ms on 172.24.0.3 (executor 0) (4/4)
[2024-10-12T00:41:48.567+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2024-10-12T00:41:48.568+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO DAGScheduler: ResultStage 11 (toPandas at /spark-scripts/taxi_etl.py:122) finished in 2.118 s
[2024-10-12T00:41:48.569+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-10-12T00:41:48.569+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2024-10-12T00:41:48.571+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO DAGScheduler: Job 8 finished: toPandas at /spark-scripts/taxi_etl.py:122, took 2.140004 s
[2024-10-12T00:41:48.572+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed taskresult_47 on 172.24.0.3:41503 in memory (size: 8.8 MiB, free: 2.2 GiB)
[2024-10-12T00:41:48.756+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_13_piece0 on yellow-cab-airflow-scheduler:34119 in memory (size: 23.9 KiB, free: 1048.7 MiB)
[2024-10-12T00:41:48.759+0000] {spark_submit.py:649} INFO - 24/10/12 00:41:48 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.24.0.3:41503 in memory (size: 23.9 KiB, free: 2.2 GiB)
[2024-10-12T00:43:03.809+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO FileSourceStrategy: Pushed Filters:
[2024-10-12T00:43:03.814+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO FileSourceStrategy: Post-Scan Filters: atleastnnonnulls(4, tpep_pickup_datetime#32, tpep_dropoff_datetime#33, pickup_longitude#36, pickup_latitude#37)
[2024-10-12T00:43:03.838+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 204.7 KiB, free 1048.1 MiB)
[2024-10-12T00:43:03.855+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1048.1 MiB)
[2024-10-12T00:43:03.861+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 35.6 KiB, free: 1048.7 MiB)
[2024-10-12T00:43:03.864+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO SparkContext: Created broadcast 14 from toPandas at /spark-scripts/taxi_etl.py:125
[2024-10-12T00:43:03.872+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2024-10-12T00:43:03.891+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO SparkContext: Starting job: toPandas at /spark-scripts/taxi_etl.py:125
[2024-10-12T00:43:03.895+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO DAGScheduler: Got job 9 (toPandas at /spark-scripts/taxi_etl.py:125) with 13 output partitions
[2024-10-12T00:43:03.895+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO DAGScheduler: Final stage: ResultStage 12 (toPandas at /spark-scripts/taxi_etl.py:125)
[2024-10-12T00:43:03.896+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO DAGScheduler: Parents of final stage: List()
[2024-10-12T00:43:03.896+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO DAGScheduler: Missing parents: List()
[2024-10-12T00:43:03.897+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[41] at toPandas at /spark-scripts/taxi_etl.py:125), which has no missing parents
[2024-10-12T00:43:03.903+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 37.2 KiB, free 1048.1 MiB)
[2024-10-12T00:43:03.907+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 16.0 KiB, free 1048.0 MiB)
[2024-10-12T00:43:03.907+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on yellow-cab-airflow-scheduler:34119 (size: 16.0 KiB, free: 1048.7 MiB)
[2024-10-12T00:43:03.908+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
[2024-10-12T00:43:03.908+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO DAGScheduler: Submitting 13 missing tasks from ResultStage 12 (MapPartitionsRDD[41] at toPandas at /spark-scripts/taxi_etl.py:125) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2024-10-12T00:43:03.909+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 13 tasks resource profile 0
[2024-10-12T00:43:03.911+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 48) (172.24.0.3, executor 0, partition 0, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:03.911+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 49) (172.24.0.3, executor 0, partition 1, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:03.912+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 50) (172.24.0.3, executor 0, partition 2, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:03.913+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 51) (172.24.0.3, executor 0, partition 3, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:03.985+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.24.0.3:41503 (size: 16.0 KiB, free: 2.2 GiB)
[2024-10-12T00:43:04.088+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.24.0.3:41503 (size: 35.6 KiB, free: 2.2 GiB)
[2024-10-12T00:43:12.558+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:12 INFO BlockManagerInfo: Added taskresult_50 in memory on 172.24.0.3:41503 (size: 110.6 MiB, free: 2.1 GiB)
[2024-10-12T00:43:12.631+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:12 INFO TaskSetManager: Starting task 4.0 in stage 12.0 (TID 52) (172.24.0.3, executor 0, partition 4, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:12.866+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:12 INFO BlockManagerInfo: Added taskresult_48 in memory on 172.24.0.3:41503 (size: 112.0 MiB, free: 2.0 GiB)
[2024-10-12T00:43:12.889+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:12 INFO TaskSetManager: Starting task 5.0 in stage 12.0 (TID 53) (172.24.0.3, executor 0, partition 5, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:12.890+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:12 INFO BlockManagerInfo: Added taskresult_51 in memory on 172.24.0.3:41503 (size: 111.9 MiB, free: 1942.9 MiB)
[2024-10-12T00:43:12.898+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:12 INFO TaskSetManager: Starting task 6.0 in stage 12.0 (TID 54) (172.24.0.3, executor 0, partition 6, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:13.344+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:13 INFO BlockManagerInfo: Added taskresult_49 in memory on 172.24.0.3:41503 (size: 109.7 MiB, free: 1833.2 MiB)
[2024-10-12T00:43:13.352+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:13 INFO TaskSetManager: Starting task 7.0 in stage 12.0 (TID 55) (172.24.0.3, executor 0, partition 7, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:13.807+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:13 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 50) in 9872 ms on 172.24.0.3 (executor 0) (1/13)
[2024-10-12T00:43:13.851+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:13 INFO BlockManagerInfo: Removed taskresult_50 on 172.24.0.3:41503 in memory (size: 110.6 MiB, free: 1943.8 MiB)
[2024-10-12T00:43:14.338+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:14 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 48) in 10427 ms on 172.24.0.3 (executor 0) (2/13)
[2024-10-12T00:43:14.351+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:14 INFO BlockManagerInfo: Removed taskresult_48 on 172.24.0.3:41503 in memory (size: 112.0 MiB, free: 2.0 GiB)
[2024-10-12T00:43:15.208+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:15 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 51) in 11276 ms on 172.24.0.3 (executor 0) (3/13)
[2024-10-12T00:43:15.343+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:15 INFO BlockManagerInfo: Removed taskresult_51 on 172.24.0.3:41503 in memory (size: 111.9 MiB, free: 2.1 GiB)
[2024-10-12T00:43:16.187+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:16 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 49) in 12264 ms on 172.24.0.3 (executor 0) (4/13)
[2024-10-12T00:43:16.227+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:16 INFO BlockManagerInfo: Removed taskresult_49 on 172.24.0.3:41503 in memory (size: 109.7 MiB, free: 2.2 GiB)
[2024-10-12T00:43:25.753+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO BlockManagerInfo: Added taskresult_53 in memory on 172.24.0.3:41503 (size: 112.0 MiB, free: 2.1 GiB)
[2024-10-12T00:43:25.795+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO TaskSetManager: Starting task 8.0 in stage 12.0 (TID 56) (172.24.0.3, executor 0, partition 8, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:25.826+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO BlockManagerInfo: Added taskresult_55 in memory on 172.24.0.3:41503 (size: 111.8 MiB, free: 2.0 GiB)
[2024-10-12T00:43:25.831+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO BlockManagerInfo: Added taskresult_54 in memory on 172.24.0.3:41503 (size: 112.0 MiB, free: 1941.8 MiB)
[2024-10-12T00:43:25.845+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO TaskSetManager: Starting task 9.0 in stage 12.0 (TID 57) (172.24.0.3, executor 0, partition 9, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:25.848+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO TaskSetManager: Starting task 10.0 in stage 12.0 (TID 58) (172.24.0.3, executor 0, partition 10, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:25.930+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO BlockManagerInfo: Added taskresult_52 in memory on 172.24.0.3:41503 (size: 111.9 MiB, free: 1829.9 MiB)
[2024-10-12T00:43:25.946+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:25 INFO TaskSetManager: Starting task 11.0 in stage 12.0 (TID 59) (172.24.0.3, executor 0, partition 11, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:27.141+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:27 INFO TaskSetManager: Finished task 5.0 in stage 12.0 (TID 53) in 14246 ms on 172.24.0.3 (executor 0) (5/13)
[2024-10-12T00:43:27.191+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:27 INFO BlockManagerInfo: Removed taskresult_53 on 172.24.0.3:41503 in memory (size: 112.0 MiB, free: 1941.8 MiB)
[2024-10-12T00:43:28.035+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:28 WARN BlockManager: Failed to fetch remote block taskresult_54 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:28.038+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:28.038+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:28.039+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:28.039+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:28.040+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:28.040+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:28.041+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:28.042+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:28.043+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:28.044+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:28.044+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:28.045+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:28.045+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:28.046+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:28.046+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:28.047+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:28.047+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:28.048+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:28.049+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:28.053+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:28.054+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:28.056+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:28.056+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:28.057+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:28.059+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:28.060+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:28.060+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:28.061+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:28.062+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:28.062+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:28.063+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:28.064+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:28.065+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:28.065+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:28.066+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:28.066+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:28.067+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:28.068+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.068+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.069+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:28.069+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:28.070+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.070+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.072+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:28.072+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:28.073+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.073+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.077+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:28.078+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:28.079+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.079+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.081+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:28.081+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:28.082+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.083+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:28.084+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:28.084+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:28.085+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:28.086+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:28.088+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:28.089+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:28.091+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:28.092+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:28.094+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:28.095+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:28.095+0000] {spark_submit.py:649} INFO - at java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:64)
[2024-10-12T00:43:28.096+0000] {spark_submit.py:649} INFO - at java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:363)
[2024-10-12T00:43:28.097+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:93)
[2024-10-12T00:43:28.098+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:28.099+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:28.100+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:28.101+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:28.102+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:28.103+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:28.104+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:28.106+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:28.107+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:28.108+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:28.109+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.111+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.112+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:28.113+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:28.114+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.114+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.115+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:28.115+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:28.116+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.116+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.117+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:28.117+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:28.118+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.118+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:28.118+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:28.118+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:28.118+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:28.118+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:28.118+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:28.120+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:28 WARN TaskSetManager: Lost task 6.0 in stage 12.0 (TID 54) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:28.120+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:28 INFO TaskSetManager: Finished task 7.0 in stage 12.0 (TID 55) in 14692 ms on 172.24.0.3 (executor 0) (6/13)
[2024-10-12T00:43:28.121+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:28 INFO BlockManagerInfo: Removed taskresult_55 on 172.24.0.3:41503 in memory (size: 111.8 MiB, free: 2.0 GiB)
[2024-10-12T00:43:29.249+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:29 INFO TaskSetManager: Finished task 4.0 in stage 12.0 (TID 52) in 16624 ms on 172.24.0.3 (executor 0) (7/13)
[2024-10-12T00:43:29.262+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:29 INFO BlockManagerInfo: Removed taskresult_52 on 172.24.0.3:41503 in memory (size: 111.9 MiB, free: 2.1 GiB)
[2024-10-12T00:43:37.782+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:37 INFO BlockManagerInfo: Added taskresult_57 in memory on 172.24.0.3:41503 (size: 111.9 MiB, free: 2.0 GiB)
[2024-10-12T00:43:37.884+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:37 INFO BlockManagerInfo: Added taskresult_59 in memory on 172.24.0.3:41503 (size: 110.8 MiB, free: 1942.9 MiB)
[2024-10-12T00:43:37.890+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:37 INFO TaskSetManager: Starting task 6.1 in stage 12.0 (TID 60) (172.24.0.3, executor 0, partition 6, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:37.900+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:37 INFO TaskSetManager: Starting task 12.0 in stage 12.0 (TID 61) (172.24.0.3, executor 0, partition 12, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:37.951+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:37 INFO BlockManagerInfo: Added taskresult_56 in memory on 172.24.0.3:41503 (size: 111.5 MiB, free: 1831.3 MiB)
[2024-10-12T00:43:37.985+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:37 INFO BlockManagerInfo: Added taskresult_58 in memory on 172.24.0.3:41503 (size: 111.8 MiB, free: 1719.5 MiB)
[2024-10-12T00:43:38.788+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:38 WARN BlockManager: Failed to fetch remote block taskresult_59 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:38.802+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:38.803+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:38.804+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:38.804+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:38.805+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:38.805+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:38.805+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:38.806+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:38.806+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:38.810+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:38.811+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:38.811+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:38.812+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:38.813+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:38.814+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:38.815+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:38.815+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:38.816+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:38.816+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:38.817+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:38.817+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:38.819+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:38.820+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:38.820+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:38.822+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:38.824+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:38.824+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:38.824+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:38.825+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:38.825+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:38.825+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:38.826+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:38.827+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:38.828+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:38.830+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:38.831+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:38.832+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:38.832+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.833+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.833+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:38.834+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:38.834+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.837+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.837+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:38.838+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:38.839+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.839+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.840+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:38.840+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:38.841+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.841+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.842+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:38.842+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:38.843+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.843+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:38.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:38.845+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:38.845+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:38.846+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:38.846+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:38.847+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:38.848+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:38.849+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:38.849+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:38.850+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:38.854+0000] {spark_submit.py:649} INFO - at java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:64)
[2024-10-12T00:43:38.855+0000] {spark_submit.py:649} INFO - at java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:363)
[2024-10-12T00:43:38.856+0000] {spark_submit.py:649} INFO - at io.netty.buffer.CompositeByteBuf.nioBuffer(CompositeByteBuf.java:1685)
[2024-10-12T00:43:38.856+0000] {spark_submit.py:649} INFO - at io.netty.buffer.AbstractDerivedByteBuf.nioBuffer(AbstractDerivedByteBuf.java:122)
[2024-10-12T00:43:38.856+0000] {spark_submit.py:649} INFO - at io.netty.buffer.AbstractByteBuf.nioBuffer(AbstractByteBuf.java:1231)
[2024-10-12T00:43:38.857+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.buffer.NettyManagedBuffer.nioByteBuffer(NettyManagedBuffer.java:46)
[2024-10-12T00:43:38.857+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:94)
[2024-10-12T00:43:38.858+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:38.859+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:38.859+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:38.860+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:38.861+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:38.861+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:38.861+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:38.862+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:38.862+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:38.862+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:38.863+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.863+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.863+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:38.864+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:38.864+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.866+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.866+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:38.867+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:38.867+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.868+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.868+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:38.868+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:38.869+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:38.869+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:38.870+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:38.870+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:38 WARN TaskSetManager: Lost task 11.0 in stage 12.0 (TID 59) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:38.870+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:38 INFO TaskSetManager: Starting task 11.1 in stage 12.0 (TID 62) (172.24.0.3, executor 0, partition 11, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:39.103+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:39 WARN BlockManager: Failed to fetch remote block taskresult_57 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:39.104+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:39.104+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:39.105+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:39.107+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:39.112+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:39.114+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:39.114+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:39.115+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:39.115+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:39.115+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:39.115+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:39.115+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:39.116+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:39.116+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:39.118+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:39.119+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:39.119+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:39.119+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:39.119+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:39.119+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:39.119+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:39.123+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:39.124+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:39.124+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:39.127+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:39.128+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:39.128+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:39.129+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:39.130+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:39.131+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:39.131+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:39.132+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:39.132+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:39.132+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:39.133+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:39.134+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.135+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.135+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:39.135+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:39.135+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.135+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:39.135+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:39.135+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:39.136+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:39.136+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:39.136+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:39.136+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:39.136+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:39.136+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:39.136+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:39.137+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:39.137+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:39 WARN TaskSetManager: Lost task 9.0 in stage 12.0 (TID 57) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:39.137+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:39 INFO TaskSetManager: Starting task 9.1 in stage 12.0 (TID 63) (172.24.0.3, executor 0, partition 9, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:39.677+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:39 WARN BlockManager: Failed to fetch remote block taskresult_56 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:39.680+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:39.682+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:39.686+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:39.686+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:39.687+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:39.687+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:39.687+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:39.688+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:39.688+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:39.689+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:39.691+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:39.692+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:39.693+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:39.693+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:39.694+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:39.694+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:39.694+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:39.695+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:39.696+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:39.696+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:39.697+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:39.697+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:39.698+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:39.699+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:39.700+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:39.700+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:39.701+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:39.701+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:39.701+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:39.701+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:39.702+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:39.703+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:39.703+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:39.703+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:39.703+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:39.704+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:39.704+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:39.705+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.705+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.705+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:39.705+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:39.705+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.705+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.705+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:39.706+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:39.706+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.706+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.706+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:39.706+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:39.707+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.707+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:39.707+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:39.707+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:39.707+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:39.708+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:39.708+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:39.709+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:39.710+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:39.710+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:39.710+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:39.711+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:39.711+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:39.711+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:39.711+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:39.711+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:39.712+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:39 WARN TaskSetManager: Lost task 8.0 in stage 12.0 (TID 56) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:40.093+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:40 WARN BlockManager: Failed to fetch remote block taskresult_58 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:40.094+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:40.094+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:40.094+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:40.094+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:40.095+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:40.095+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:40.095+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:40.095+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:40.095+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:40.095+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:40.095+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:40.096+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:40.097+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:40.098+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:40.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:40.100+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:40.100+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:40.100+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:40.100+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:40.100+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:40.100+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:40.100+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:40.101+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:40 WARN TaskSetManager: Lost task 10.0 in stage 12.0 (TID 58) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:46.321+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:46 INFO BlockManagerInfo: Added taskresult_61 in memory on 172.24.0.3:41503 (size: 80.7 MiB, free: 1638.8 MiB)
[2024-10-12T00:43:46.396+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:46 INFO TaskSetManager: Starting task 10.1 in stage 12.0 (TID 64) (172.24.0.3, executor 0, partition 10, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:47.263+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:47 INFO TaskSetManager: Finished task 12.0 in stage 12.0 (TID 61) in 9359 ms on 172.24.0.3 (executor 0) (8/13)
[2024-10-12T00:43:47.303+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:47 INFO BlockManagerInfo: Removed taskresult_61 on 172.24.0.3:41503 in memory (size: 80.7 MiB, free: 1719.5 MiB)
[2024-10-12T00:43:49.744+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:49 INFO BlockManagerInfo: Added taskresult_60 in memory on 172.24.0.3:41503 (size: 112.0 MiB, free: 1607.5 MiB)
[2024-10-12T00:43:49.768+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:49 INFO TaskSetManager: Starting task 8.1 in stage 12.0 (TID 65) (172.24.0.3, executor 0, partition 8, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:50.409+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:50 INFO BlockManagerInfo: Added taskresult_62 in memory on 172.24.0.3:41503 (size: 110.8 MiB, free: 1496.7 MiB)
[2024-10-12T00:43:50.417+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:50 WARN BlockManager: Failed to fetch remote block taskresult_60 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:50.419+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:50.420+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:50.420+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:50.422+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:50.423+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:50.424+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:50.426+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:50.426+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:50.427+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:50.428+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:50.428+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:50.429+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:50.430+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:50.430+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:50.431+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:50.431+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:50.431+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:50.432+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:50.432+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:50.432+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:50.433+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:50.433+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:50.433+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:50.434+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:50.434+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:50.434+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:50.435+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:50.435+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:50.436+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:50.436+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:50.437+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:50.437+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:50.437+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:50.438+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:50.438+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:50.438+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:50.439+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:50.439+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:50.439+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:50.439+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:50.440+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:50.440+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:50.440+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:50.441+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:50.441+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:50.441+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:50.442+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:50.442+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:50.442+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:50.443+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:50.443+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:50.443+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:50.444+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:50.444+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:50.444+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:50.444+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:50.444+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:50.445+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:50.445+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:50.445+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:50.445+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:50.445+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:50.445+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:50.446+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:50.447+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:50.449+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:50 WARN TaskSetManager: Lost task 6.1 in stage 12.0 (TID 60) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:50.458+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:50 INFO TaskSetManager: Starting task 6.2 in stage 12.0 (TID 66) (172.24.0.3, executor 0, partition 6, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:50.525+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:50 INFO BlockManagerInfo: Added taskresult_63 in memory on 172.24.0.3:41503 (size: 111.9 MiB, free: 1384.9 MiB)
[2024-10-12T00:43:51.034+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:50 WARN BlockManager: Failed to fetch remote block taskresult_62 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:51.049+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:51.049+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:51.050+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:51.051+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:51.052+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:51.052+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:51.053+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:51.053+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:51.054+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:51.054+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:51.057+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:51.058+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:51.058+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:51.059+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:51.059+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:51.060+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:51.061+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:51.065+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:51.067+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:51.070+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:51.071+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:51.073+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:51.073+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:51.074+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:51.076+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:51.077+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:51.080+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:51.081+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:51.082+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:51.082+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:51.083+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:51.085+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:51.086+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:51.086+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:51.087+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:51.088+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:51.089+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:51.089+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.089+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.090+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:51.091+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:51.092+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.093+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.094+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:51.095+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:51.096+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.097+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.098+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:51.099+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:51.101+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.102+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.103+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:51.103+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:51.104+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.105+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:51.105+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:51.106+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:51.106+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:51.107+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:51.109+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:51.110+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:51.110+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:51.111+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:51.112+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:51.113+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:51.114+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:51 WARN TaskSetManager: Lost task 11.1 in stage 12.0 (TID 62) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:51.115+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:51 INFO TaskSetManager: Starting task 11.2 in stage 12.0 (TID 67) (172.24.0.3, executor 0, partition 11, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:43:51.600+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:51 WARN BlockManager: Failed to fetch remote block taskresult_63 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:43:51.603+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:43:51.603+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:43:51.603+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:43:51.604+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:43:51.604+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:43:51.604+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:43:51.604+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:43:51.604+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:43:51.605+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:43:51.605+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:43:51.605+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:43:51.605+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:43:51.605+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:43:51.605+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:43:51.605+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:43:51.606+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:43:51.606+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:43:51.606+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:43:51.606+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:43:51.606+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:43:51.607+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:43:51.607+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:43:51.607+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:43:51.607+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:43:51.607+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:43:51.607+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:43:51.607+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:43:51.608+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:43:51.608+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:43:51.608+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:43:51.608+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:43:51.608+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:43:51.608+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:43:51.609+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:43:51.609+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:43:51.609+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:43:51.609+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:51.609+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.609+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.609+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:43:51.610+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:43:51.610+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.610+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.610+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:43:51.610+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:51.610+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.610+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:43:51.611+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:43:51.612+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:43:51.612+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:43:51.612+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:43:51.612+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:43:51.612+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:43:51.613+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:43:51.613+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:43:51.614+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:43:51.614+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:43:51.614+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:43:51.615+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:51 WARN TaskSetManager: Lost task 9.1 in stage 12.0 (TID 63) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:43:59.319+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:59 INFO BlockManagerInfo: Added taskresult_64 in memory on 172.24.0.3:41503 (size: 111.8 MiB, free: 1273.0 MiB)
[2024-10-12T00:43:59.345+0000] {spark_submit.py:649} INFO - 24/10/12 00:43:59 INFO TaskSetManager: Starting task 9.2 in stage 12.0 (TID 68) (172.24.0.3, executor 0, partition 9, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:44:00.183+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:00 WARN BlockManager: Failed to fetch remote block taskresult_64 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:44:00.192+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:44:00.193+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:44:00.193+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:44:00.194+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:44:00.194+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:00.195+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:00.195+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:00.196+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:00.196+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:00.197+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:00.197+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:00.197+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:00.198+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:00.201+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:00.202+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:00.202+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:00.202+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:44:00.203+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:44:00.203+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:44:00.203+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:44:00.204+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:44:00.205+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:44:00.205+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:44:00.206+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:44:00.206+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:44:00.206+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:44:00.207+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:44:00.207+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:44:00.207+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:44:00.208+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:44:00.208+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:44:00.208+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:44:00.209+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:44:00.210+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:44:00.210+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:44:00.210+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:44:00.211+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:00.211+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:00.211+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:00.212+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:44:00.212+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:44:00.212+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:00.213+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:00.213+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:44:00.214+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:00.215+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:00.215+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:00.216+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:44:00.216+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:00.216+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:00.216+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:00.217+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:44:00.217+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:44:00.217+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:00.217+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:44:00.218+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:44:00.218+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:44:00.218+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:44:00.219+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:44:00.219+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:44:00.219+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:44:00.220+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:44:00.220+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:44:00.221+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:44:00.221+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:00.223+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:00 WARN TaskSetManager: Lost task 10.1 in stage 12.0 (TID 64) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:44:02.786+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:02 INFO BlockManagerInfo: Added taskresult_65 in memory on 172.24.0.3:41503 (size: 111.5 MiB, free: 1161.5 MiB)
[2024-10-12T00:44:02.862+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:02 INFO BlockManagerInfo: Added taskresult_66 in memory on 172.24.0.3:41503 (size: 112.0 MiB, free: 1049.5 MiB)
[2024-10-12T00:44:02.865+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:02 INFO TaskSetManager: Starting task 10.2 in stage 12.0 (TID 69) (172.24.0.3, executor 0, partition 10, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:44:03.343+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 WARN BlockManager: Failed to fetch remote block taskresult_65 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:44:03.344+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:44:03.344+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:44:03.345+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:44:03.345+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:44:03.346+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:03.346+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:03.346+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:03.346+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:03.347+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:03.347+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:03.348+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:03.349+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:03.349+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:03.349+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:03.349+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:03.349+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:03.350+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:44:03.350+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:44:03.350+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:44:03.351+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:44:03.351+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:44:03.352+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:44:03.352+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:44:03.352+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:44:03.353+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:44:03.353+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:44:03.353+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:44:03.353+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:44:03.354+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:44:03.354+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:44:03.354+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:44:03.355+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:44:03.356+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:44:03.359+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:44:03.360+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:44:03.364+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:44:03.365+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.365+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.366+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.366+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:44:03.366+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:44:03.366+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:44:03.367+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.368+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:44:03.368+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:44:03.368+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:44:03.368+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:44:03.368+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:44:03.368+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:44:03.368+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:44:03.369+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:44:03.369+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:44:03.369+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:44:03.369+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:03.371+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 WARN TaskSetManager: Lost task 8.1 in stage 12.0 (TID 65) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:44:03.372+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 INFO TaskSetManager: Starting task 8.2 in stage 12.0 (TID 70) (172.24.0.3, executor 0, partition 8, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:44:03.494+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 WARN BlockManager: Failed to fetch remote block taskresult_66 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:44:03.495+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:44:03.496+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:44:03.497+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:44:03.497+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:44:03.498+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:03.500+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:03.501+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:03.502+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:03.502+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:03.503+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:03.504+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:03.505+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:03.505+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:03.506+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:03.507+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:03.507+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:03.508+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:44:03.508+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:44:03.508+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:44:03.508+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:44:03.508+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:44:03.508+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:44:03.509+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:44:03.512+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:44:03.513+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:44:03.514+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:44:03.514+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:44:03.514+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:44:03.514+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:44:03.515+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:44:03.515+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:44:03.515+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:44:03.515+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:44:03.515+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:44:03.515+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:44:03.516+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:44:03.516+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.516+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.516+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.517+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:44:03.517+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:44:03.517+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.518+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.519+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:44:03.519+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.519+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.520+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.520+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:44:03.520+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.520+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.520+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.520+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:44:03.521+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:44:03.522+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:44:03.522+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:44:03.522+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:44:03.522+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:03.522+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 WARN TaskSetManager: Lost task 6.2 in stage 12.0 (TID 66) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:44:03.593+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 INFO BlockManagerInfo: Added taskresult_67 in memory on 172.24.0.3:41503 (size: 110.8 MiB, free: 938.7 MiB)
[2024-10-12T00:44:03.609+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 INFO TaskSetManager: Starting task 6.3 in stage 12.0 (TID 71) (172.24.0.3, executor 0, partition 6, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:44:03.833+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 WARN BlockManager: Failed to fetch remote block taskresult_67 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:44:03.834+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:44:03.835+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:44:03.835+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:44:03.835+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:44:03.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:03.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:03.836+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:03.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:03.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:03.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:44:03.837+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:44:03.838+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:44:03.838+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:44:03.838+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:44:03.839+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:44:03.839+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:44:03.839+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:44:03.839+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:44:03.839+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:44:03.839+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:44:03.839+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:44:03.840+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:44:03.840+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:44:03.840+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:44:03.840+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:44:03.840+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:44:03.840+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:44:03.841+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:44:03.841+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:44:03.841+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.841+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.841+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.841+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:44:03.842+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:44:03.842+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.842+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.842+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:44:03.842+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.842+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.843+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.843+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:44:03.843+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:03.843+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.843+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:03.843+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:44:03.844+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:44:03.845+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:44:03.845+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:03.845+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:03 WARN TaskSetManager: Lost task 11.2 in stage 12.0 (TID 67) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:44:08.721+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:08 INFO BlockManagerInfo: Added taskresult_68 in memory on 172.24.0.3:41503 (size: 111.9 MiB, free: 826.9 MiB)
[2024-10-12T00:44:08.741+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:08 INFO TaskSetManager: Starting task 11.3 in stage 12.0 (TID 72) (172.24.0.3, executor 0, partition 11, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:44:09.204+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:09 WARN BlockManager: Failed to fetch remote block taskresult_68 from [BlockManagerId(0, 172.24.0.3, 41503, None)] after 1 fetch failures. Most recent failure cause:
[2024-10-12T00:44:09.206+0000] {spark_submit.py:649} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-10-12T00:44:09.206+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-10-12T00:44:09.207+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:44:09.209+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:44:09.209+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:09.212+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:09.213+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:09.213+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:09.214+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:09.214+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:09.214+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:09.215+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:09.215+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:09.216+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:09.216+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:09.216+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:09.216+0000] {spark_submit.py:649} INFO - Caused by: java.util.concurrent.ExecutionException: Boxed Error
[2024-10-12T00:44:09.217+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.resolver(Promise.scala:87)
[2024-10-12T00:44:09.217+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
[2024-10-12T00:44:09.217+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
[2024-10-12T00:44:09.218+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-10-12T00:44:09.218+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-10-12T00:44:09.218+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-10-12T00:44:09.218+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure(Promise.scala:104)
[2024-10-12T00:44:09.218+0000] {spark_submit.py:649} INFO - at scala.concurrent.Promise.failure$(Promise.scala:104)
[2024-10-12T00:44:09.218+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
[2024-10-12T00:44:09.219+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchSuccess(BlockTransferService.scala:98)
[2024-10-12T00:44:09.222+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferSuccess(BlockFetchingListener.java:37)
[2024-10-12T00:44:09.222+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferSuccess(BlockTransferService.scala:81)
[2024-10-12T00:44:09.223+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.handleBlockTransferSuccess(RetryingBlockTransferor.java:266)
[2024-10-12T00:44:09.223+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor$RetryingBlockTransferListener.onBlockFetchSuccess(RetryingBlockTransferor.java:302)
[2024-10-12T00:44:09.224+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.OneForOneBlockFetcher$ChunkCallback.onSuccess(OneForOneBlockFetcher.java:286)
[2024-10-12T00:44:09.224+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:172)
[2024-10-12T00:44:09.224+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
[2024-10-12T00:44:09.224+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
[2024-10-12T00:44:09.224+0000] {spark_submit.py:649} INFO - at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
[2024-10-12T00:44:09.224+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:09.225+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:09.225+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:09.225+0000] {spark_submit.py:649} INFO - at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[2024-10-12T00:44:09.225+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
[2024-10-12T00:44:09.225+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:09.225+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:09.225+0000] {spark_submit.py:649} INFO - at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
[2024-10-12T00:44:09.226+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:44:09.227+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:44:09.228+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:44:09.228+0000] {spark_submit.py:649} INFO - ... 1 more
[2024-10-12T00:44:09.228+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:09.228+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:09 WARN TaskSetManager: Lost task 9.2 in stage 12.0 (TID 68) (172.24.0.3 executor 0): TaskResultLost (result lost from block manager)
[2024-10-12T00:44:11.768+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO BlockManagerInfo: Added taskresult_69 in memory on 172.24.0.3:41503 (size: 111.8 MiB, free: 715.1 MiB)
[2024-10-12T00:44:11.808+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO TaskSetManager: Starting task 9.3 in stage 12.0 (TID 73) (172.24.0.3, executor 0, partition 9, PROCESS_LOCAL, 9994 bytes)
[2024-10-12T00:44:11.816+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 WARN TaskSetManager: Lost task 6.3 in stage 12.0 (TID 71) (172.24.0.3 executor 0): java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:11.817+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Double.valueOf(Double.java:632)
[2024-10-12T00:44:11.818+0000] {spark_submit.py:649} INFO - at scala.runtime.BoxesRunTime.boxToDouble(BoxesRunTime.java:81)
[2024-10-12T00:44:11.819+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:207)
[2024-10-12T00:44:11.820+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1765/0x00000070019ef3b8.apply(Unknown Source)
[2024-10-12T00:44:11.821+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)
[2024-10-12T00:44:11.822+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:203)
[2024-10-12T00:44:11.823+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1742/0x00000070019e7b98.apply(Unknown Source)
[2024-10-12T00:44:11.823+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)
[2024-10-12T00:44:11.824+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)
[2024-10-12T00:44:11.825+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1745/0x00000070019e8a88.apply(Unknown Source)
[2024-10-12T00:44:11.826+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)
[2024-10-12T00:44:11.826+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1755/0x00000070019eca38.apply(Unknown Source)
[2024-10-12T00:44:11.827+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)
[2024-10-12T00:44:11.827+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)
[2024-10-12T00:44:11.828+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1758/0x00000070019edbd8.apply(Unknown Source)
[2024-10-12T00:44:11.829+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-10-12T00:44:11.830+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-10-12T00:44:11.831+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.831+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)
[2024-10-12T00:44:11.832+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.833+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
[2024-10-12T00:44:11.833+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2024-10-12T00:44:11.834+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
[2024-10-12T00:44:11.834+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.834+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.835+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
[2024-10-12T00:44:11.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan$$Lambda$921/0x0000007001646c90.apply(Unknown Source)
[2024-10-12T00:44:11.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
[2024-10-12T00:44:11.836+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
[2024-10-12T00:44:11.837+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD$$Lambda$922/0x0000007001647068.apply(Unknown Source)
[2024-10-12T00:44:11.838+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2024-10-12T00:44:11.839+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
[2024-10-12T00:44:11.839+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:44:11.840+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 ERROR TaskSetManager: Task 6 in stage 12.0 failed 4 times; aborting job
[2024-10-12T00:44:11.843+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO TaskSchedulerImpl: Cancelling stage 12
[2024-10-12T00:44:11.844+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage cancelled: Job aborted due to stage failure: Task 6 in stage 12.0 failed 4 times, most recent failure: Lost task 6.3 in stage 12.0 (TID 71) (172.24.0.3 executor 0): java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:11.844+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Double.valueOf(Double.java:632)
[2024-10-12T00:44:11.845+0000] {spark_submit.py:649} INFO - at scala.runtime.BoxesRunTime.boxToDouble(BoxesRunTime.java:81)
[2024-10-12T00:44:11.846+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:207)
[2024-10-12T00:44:11.847+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1765/0x00000070019ef3b8.apply(Unknown Source)
[2024-10-12T00:44:11.849+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)
[2024-10-12T00:44:11.850+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:203)
[2024-10-12T00:44:11.850+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1742/0x00000070019e7b98.apply(Unknown Source)
[2024-10-12T00:44:11.850+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)
[2024-10-12T00:44:11.851+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)
[2024-10-12T00:44:11.853+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1745/0x00000070019e8a88.apply(Unknown Source)
[2024-10-12T00:44:11.853+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)
[2024-10-12T00:44:11.854+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1755/0x00000070019eca38.apply(Unknown Source)
[2024-10-12T00:44:11.854+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)
[2024-10-12T00:44:11.855+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)
[2024-10-12T00:44:11.855+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1758/0x00000070019edbd8.apply(Unknown Source)
[2024-10-12T00:44:11.855+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-10-12T00:44:11.855+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-10-12T00:44:11.856+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.856+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)
[2024-10-12T00:44:11.856+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.857+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
[2024-10-12T00:44:11.857+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2024-10-12T00:44:11.858+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
[2024-10-12T00:44:11.859+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.860+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.860+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
[2024-10-12T00:44:11.861+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan$$Lambda$921/0x0000007001646c90.apply(Unknown Source)
[2024-10-12T00:44:11.862+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
[2024-10-12T00:44:11.862+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
[2024-10-12T00:44:11.863+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD$$Lambda$922/0x0000007001647068.apply(Unknown Source)
[2024-10-12T00:44:11.863+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2024-10-12T00:44:11.867+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
[2024-10-12T00:44:11.867+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:44:11.868+0000] {spark_submit.py:649} INFO - Driver stacktrace:
[2024-10-12T00:44:11.868+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO TransportClientFactory: Found inactive connection to /172.24.0.3:41503, creating a new one.
[2024-10-12T00:44:11.869+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO TaskSchedulerImpl: Stage 12 was cancelled
[2024-10-12T00:44:11.870+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO DAGScheduler: ResultStage 12 (toPandas at /spark-scripts/taxi_etl.py:125) failed in 67.956 s due to Job aborted due to stage failure: Task 6 in stage 12.0 failed 4 times, most recent failure: Lost task 6.3 in stage 12.0 (TID 71) (172.24.0.3 executor 0): java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:11.870+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Double.valueOf(Double.java:632)
[2024-10-12T00:44:11.871+0000] {spark_submit.py:649} INFO - at scala.runtime.BoxesRunTime.boxToDouble(BoxesRunTime.java:81)
[2024-10-12T00:44:11.871+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:207)
[2024-10-12T00:44:11.872+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1765/0x00000070019ef3b8.apply(Unknown Source)
[2024-10-12T00:44:11.872+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)
[2024-10-12T00:44:11.873+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:203)
[2024-10-12T00:44:11.873+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1742/0x00000070019e7b98.apply(Unknown Source)
[2024-10-12T00:44:11.873+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)
[2024-10-12T00:44:11.874+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)
[2024-10-12T00:44:11.874+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1745/0x00000070019e8a88.apply(Unknown Source)
[2024-10-12T00:44:11.875+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)
[2024-10-12T00:44:11.876+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1755/0x00000070019eca38.apply(Unknown Source)
[2024-10-12T00:44:11.876+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)
[2024-10-12T00:44:11.877+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)
[2024-10-12T00:44:11.877+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1758/0x00000070019edbd8.apply(Unknown Source)
[2024-10-12T00:44:11.878+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-10-12T00:44:11.878+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-10-12T00:44:11.878+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.878+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)
[2024-10-12T00:44:11.878+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.878+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
[2024-10-12T00:44:11.878+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan$$Lambda$921/0x0000007001646c90.apply(Unknown Source)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD$$Lambda$922/0x0000007001647068.apply(Unknown Source)
[2024-10-12T00:44:11.879+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - Driver stacktrace:
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO DAGScheduler: Job 9 failed: toPandas at /spark-scripts/taxi_etl.py:125, took 67.972710 s
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - java.io.IOException: Failed to connect to /172.24.0.3:41503
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)
[2024-10-12T00:44:11.880+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
[2024-10-12T00:44:11.881+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:131)
[2024-10-12T00:44:11.881+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)
[2024-10-12T00:44:11.881+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:152)
[2024-10-12T00:44:11.881+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:151)
[2024-10-12T00:44:11.881+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:102)
[2024-10-12T00:44:11.881+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:11.881+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:11.882+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /172.24.0.3:41503
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - Caused by: java.net.ConnectException: Connection refused
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - at java.base/sun.nio.ch.Net.pollConnect(Native Method)
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
[2024-10-12T00:44:11.883+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
[2024-10-12T00:44:11.884+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-10-12T00:44:11.884+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-10-12T00:44:11.884+0000] {spark_submit.py:649} INFO - at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-10-12T00:44:11.884+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-10-12T00:44:11.884+0000] {spark_submit.py:649} INFO - at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-10-12T00:44:11.884+0000] {spark_submit.py:649} INFO - at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-10-12T00:44:11.884+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:11.885+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 INFO RetryingBlockTransferor: Retrying fetch (1/3) for 1 outstanding blocks after 5000 ms
[2024-10-12T00:44:11.885+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 WARN TaskSetManager: Lost task 8.2 in stage 12.0 (TID 70) (172.24.0.3 executor 0): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 6 in stage 12.0 failed 4 times, most recent failure: Lost task 6.3 in stage 12.0 (TID 71) (172.24.0.3 executor 0): java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:11.885+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Double.valueOf(Double.java:632)
[2024-10-12T00:44:11.885+0000] {spark_submit.py:649} INFO - at scala.runtime.BoxesRunTime.boxToDouble(BoxesRunTime.java:81)
[2024-10-12T00:44:11.885+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:207)
[2024-10-12T00:44:11.885+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1765/0x00000070019ef3b8.apply(Unknown Source)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:203)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1742/0x00000070019e7b98.apply(Unknown Source)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1745/0x00000070019e8a88.apply(Unknown Source)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)
[2024-10-12T00:44:11.886+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1755/0x00000070019eca38.apply(Unknown Source)
[2024-10-12T00:44:11.887+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)
[2024-10-12T00:44:11.887+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)
[2024-10-12T00:44:11.887+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1758/0x00000070019edbd8.apply(Unknown Source)
[2024-10-12T00:44:11.887+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-10-12T00:44:11.887+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-10-12T00:44:11.887+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.887+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
[2024-10-12T00:44:11.888+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan$$Lambda$921/0x0000007001646c90.apply(Unknown Source)
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD$$Lambda$922/0x0000007001647068.apply(Unknown Source)
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - Driver stacktrace:)
[2024-10-12T00:44:11.889+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:11 WARN TaskSetManager: Lost task 11.3 in stage 12.0 (TID 72) (172.24.0.3 executor 0): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 6 in stage 12.0 failed 4 times, most recent failure: Lost task 6.3 in stage 12.0 (TID 71) (172.24.0.3 executor 0): java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Double.valueOf(Double.java:632)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at scala.runtime.BoxesRunTime.boxToDouble(BoxesRunTime.java:81)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:207)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1765/0x00000070019ef3b8.apply(Unknown Source)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:203)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1742/0x00000070019e7b98.apply(Unknown Source)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)
[2024-10-12T00:44:11.890+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1745/0x00000070019e8a88.apply(Unknown Source)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1755/0x00000070019eca38.apply(Unknown Source)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1758/0x00000070019edbd8.apply(Unknown Source)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.891+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan$$Lambda$921/0x0000007001646c90.apply(Unknown Source)
[2024-10-12T00:44:11.892+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
[2024-10-12T00:44:11.893+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
[2024-10-12T00:44:11.893+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD$$Lambda$922/0x0000007001647068.apply(Unknown Source)
[2024-10-12T00:44:11.893+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2024-10-12T00:44:11.893+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
[2024-10-12T00:44:11.893+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:44:11.893+0000] {spark_submit.py:649} INFO - Driver stacktrace:)
[2024-10-12T00:44:12.110+0000] {spark_submit.py:649} INFO - Traceback (most recent call last):
[2024-10-12T00:44:12.110+0000] {spark_submit.py:649} INFO - File "/spark-scripts/taxi_etl.py", line 131, in <module>
[2024-10-12T00:44:12.113+0000] {spark_submit.py:649} INFO - main()
[2024-10-12T00:44:12.113+0000] {spark_submit.py:649} INFO - File "/spark-scripts/taxi_etl.py", line 125, in main
[2024-10-12T00:44:12.113+0000] {spark_submit.py:649} INFO - fact_trip_write = client.load_table_from_dataframe(fact_trip.toPandas(), f"{PROJECT_ID}.{DATASET_ID}.fact_trip", job_config=job_config)
[2024-10-12T00:44:12.114+0000] {spark_submit.py:649} INFO - File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py", line 202, in toPandas
[2024-10-12T00:44:12.120+0000] {spark_submit.py:649} INFO - File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 1261, in collect
[2024-10-12T00:44:12.120+0000] {spark_submit.py:649} INFO - File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
[2024-10-12T00:44:12.121+0000] {spark_submit.py:649} INFO - File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
[2024-10-12T00:44:12.121+0000] {spark_submit.py:649} INFO - File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
[2024-10-12T00:44:12.164+0000] {spark_submit.py:649} INFO - py4j.protocol.Py4JJavaError: An error occurred while calling o160.collectToPython.
[2024-10-12T00:44:12.164+0000] {spark_submit.py:649} INFO - : org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 12.0 failed 4 times, most recent failure: Lost task 6.3 in stage 12.0 (TID 71) (172.24.0.3 executor 0): java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:12.164+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Double.valueOf(Double.java:632)
[2024-10-12T00:44:12.165+0000] {spark_submit.py:649} INFO - at scala.runtime.BoxesRunTime.boxToDouble(BoxesRunTime.java:81)
[2024-10-12T00:44:12.165+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:207)
[2024-10-12T00:44:12.165+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1765/0x00000070019ef3b8.apply(Unknown Source)
[2024-10-12T00:44:12.165+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)
[2024-10-12T00:44:12.165+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:203)
[2024-10-12T00:44:12.165+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1742/0x00000070019e7b98.apply(Unknown Source)
[2024-10-12T00:44:12.165+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)
[2024-10-12T00:44:12.166+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)
[2024-10-12T00:44:12.166+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1745/0x00000070019e8a88.apply(Unknown Source)
[2024-10-12T00:44:12.166+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)
[2024-10-12T00:44:12.166+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1755/0x00000070019eca38.apply(Unknown Source)
[2024-10-12T00:44:12.166+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)
[2024-10-12T00:44:12.167+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)
[2024-10-12T00:44:12.167+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1758/0x00000070019edbd8.apply(Unknown Source)
[2024-10-12T00:44:12.167+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-10-12T00:44:12.167+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-10-12T00:44:12.167+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.168+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)
[2024-10-12T00:44:12.168+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.168+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
[2024-10-12T00:44:12.168+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2024-10-12T00:44:12.168+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
[2024-10-12T00:44:12.168+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.168+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan$$Lambda$921/0x0000007001646c90.apply(Unknown Source)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD$$Lambda$922/0x0000007001647068.apply(Unknown Source)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:44:12.169+0000] {spark_submit.py:649} INFO - Driver stacktrace:
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
[2024-10-12T00:44:12.170+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at scala.Option.foreach(Option.scala:407)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
[2024-10-12T00:44:12.171+0000] {spark_submit.py:649} INFO - at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
[2024-10-12T00:44:12.172+0000] {spark_submit.py:649} INFO - at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
[2024-10-12T00:44:12.172+0000] {spark_submit.py:649} INFO - at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
[2024-10-12T00:44:12.172+0000] {spark_submit.py:649} INFO - at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
[2024-10-12T00:44:12.172+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)
[2024-10-12T00:44:12.172+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[2024-10-12T00:44:12.172+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
[2024-10-12T00:44:12.173+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)
[2024-10-12T00:44:12.173+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.collect(RDD.scala:1048)
[2024-10-12T00:44:12.173+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)
[2024-10-12T00:44:12.173+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)
[2024-10-12T00:44:12.173+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)
[2024-10-12T00:44:12.174+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2024-10-12T00:44:12.174+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)
[2024-10-12T00:44:12.174+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
[2024-10-12T00:44:12.174+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
[2024-10-12T00:44:12.174+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
[2024-10-12T00:44:12.175+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2024-10-12T00:44:12.175+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
[2024-10-12T00:44:12.176+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)
[2024-10-12T00:44:12.177+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)
[2024-10-12T00:44:12.177+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2024-10-12T00:44:12.177+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
[2024-10-12T00:44:12.177+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2024-10-12T00:44:12.177+0000] {spark_submit.py:649} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:569)
[2024-10-12T00:44:12.177+0000] {spark_submit.py:649} INFO - at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2024-10-12T00:44:12.177+0000] {spark_submit.py:649} INFO - at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - at py4j.Gateway.invoke(Gateway.java:282)
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - Caused by: java.lang.OutOfMemoryError: Java heap space
[2024-10-12T00:44:12.178+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Double.valueOf(Double.java:632)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at scala.runtime.BoxesRunTime.boxToDouble(BoxesRunTime.java:81)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:207)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1765/0x00000070019ef3b8.apply(Unknown Source)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:203)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1742/0x00000070019e7b98.apply(Unknown Source)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)
[2024-10-12T00:44:12.179+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$Lambda$1745/0x00000070019e8a88.apply(Unknown Source)
[2024-10-12T00:44:12.180+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)
[2024-10-12T00:44:12.180+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1755/0x00000070019eca38.apply(Unknown Source)
[2024-10-12T00:44:12.180+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)
[2024-10-12T00:44:12.180+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)
[2024-10-12T00:44:12.180+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.csv.UnivocityParser$$$Lambda$1758/0x00000070019edbd8.apply(Unknown Source)
[2024-10-12T00:44:12.180+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-10-12T00:44:12.180+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-10-12T00:44:12.181+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
[2024-10-12T00:44:12.182+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SparkPlan$$Lambda$921/0x0000007001646c90.apply(Unknown Source)
[2024-10-12T00:44:12.182+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
[2024-10-12T00:44:12.182+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
[2024-10-12T00:44:12.182+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD$$Lambda$922/0x0000007001647068.apply(Unknown Source)
[2024-10-12T00:44:12.182+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2024-10-12T00:44:12.182+0000] {spark_submit.py:649} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
[2024-10-12T00:44:12.182+0000] {spark_submit.py:649} INFO - 
[2024-10-12T00:44:12.930+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:12 INFO SparkContext: Invoking stop() from shutdown hook
[2024-10-12T00:44:12.931+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:12 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2024-10-12T00:44:12.959+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:12 INFO SparkUI: Stopped Spark web UI at http://yellow-cab-airflow-scheduler:4040
[2024-10-12T00:44:12.965+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:12 INFO StandaloneSchedulerBackend: Shutting down all executors
[2024-10-12T00:44:12.965+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:12 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[2024-10-12T00:44:12.975+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:12 ERROR Utils: Uncaught exception in thread task-result-getter-3
[2024-10-12T00:44:12.976+0000] {spark_submit.py:649} INFO - java.lang.InterruptedException
[2024-10-12T00:44:12.978+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1048)
[2024-10-12T00:44:12.979+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)
[2024-10-12T00:44:12.980+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)
[2024-10-12T00:44:12.981+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
[2024-10-12T00:44:12.981+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
[2024-10-12T00:44:12.982+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:44:12.982+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:44:12.982+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:12.982+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:12.983+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:12.984+0000] {spark_submit.py:649} INFO - Exception in thread "task-result-getter-3" java.lang.InterruptedException
[2024-10-12T00:44:12.984+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1048)
[2024-10-12T00:44:12.984+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)
[2024-10-12T00:44:12.985+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)
[2024-10-12T00:44:12.985+0000] {spark_submit.py:649} INFO - at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
[2024-10-12T00:44:12.986+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
[2024-10-12T00:44:12.986+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-10-12T00:44:12.986+0000] {spark_submit.py:649} INFO - at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
[2024-10-12T00:44:12.986+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
[2024-10-12T00:44:12.986+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
[2024-10-12T00:44:12.986+0000] {spark_submit.py:649} INFO - at scala.Option.orElse(Option.scala:447)
[2024-10-12T00:44:12.986+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2024-10-12T00:44:12.987+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2024-10-12T00:44:13.008+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 WARN Dispatcher: Message RequestMessage(spark-master:7077, NettyRpcEndpointRef(spark://AppClient@yellow-cab-airflow-scheduler:33783), ExecutorUpdated(0,EXITED,Some(Command exited with code 52),Some(52),None)) dropped due to sparkEnv is stopped. Could not find AppClient.
[2024-10-12T00:44:13.045+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 WARN Dispatcher: Message RequestMessage(spark-master:7077, NettyRpcEndpointRef(spark://AppClient@yellow-cab-airflow-scheduler:33783), ExecutorAdded(1,worker-20241011213037-172.24.0.3-36185,172.24.0.3:36185,4,4096)) dropped due to sparkEnv is stopped. Could not find AppClient.
[2024-10-12T00:44:13.055+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO MemoryStore: MemoryStore cleared
[2024-10-12T00:44:13.055+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO BlockManager: BlockManager stopped
[2024-10-12T00:44:13.057+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO BlockManagerMaster: BlockManagerMaster stopped
[2024-10-12T00:44:13.060+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2024-10-12T00:44:13.149+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO SparkContext: Successfully stopped SparkContext
[2024-10-12T00:44:13.149+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO ShutdownHookManager: Shutdown hook called
[2024-10-12T00:44:13.149+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b
[2024-10-12T00:44:13.185+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-637797d9-cbf8-4d1d-9051-46b1a51e174b/pyspark-cd10a06d-ee0a-48ea-aab9-a45d20827010
[2024-10-12T00:44:13.228+0000] {spark_submit.py:649} INFO - 24/10/12 00:44:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-21741485-f0d7-4f89-9ff8-8b8b907ff2c3
[2024-10-12T00:44:13.408+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-10-12T00:44:13.539+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 176, in execute
    self._hook.submit(self.application)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 575, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.jars.packages=org.apache.sedona:sedona-python-adapter-3.0_2.12:1.2.0-incubating,org.datasyslab:geotools-wrapper:geotools-24.0 --conf spark.jars.repositories=https://repo1.maven.org/maven2/ --conf spark.executor.memory=4g --conf spark.driver.maxResultSize=4g --conf spark.driver.memory=2g --name arrow-spark --deploy-mode client /spark-scripts/taxi_etl.py. Error code is: 1.
[2024-10-12T00:44:13.556+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=etl_yellow_cab, task_id=etl_task, run_id=manual__2024-10-12T00:13:45.785414+00:00, execution_date=20241012T001345, start_date=20241012T004057, end_date=20241012T004413
[2024-10-12T00:44:13.613+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 66 for task etl_task (Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.jars.packages=org.apache.sedona:sedona-python-adapter-3.0_2.12:1.2.0-incubating,org.datasyslab:geotools-wrapper:geotools-24.0 --conf spark.jars.repositories=https://repo1.maven.org/maven2/ --conf spark.executor.memory=4g --conf spark.driver.maxResultSize=4g --conf spark.driver.memory=2g --name arrow-spark --deploy-mode client /spark-scripts/taxi_etl.py. Error code is: 1.; 5194)
[2024-10-12T00:44:13.657+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-10-12T00:44:13.711+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-10-12T00:44:13.711+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
